<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notes on Morven&#39;s Life</title>
    <link>https://morven.life/notes/</link>
    <description>Recent content in Notes on Morven&#39;s Life</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Aug 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://morven.life/notes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>深入理解GoTemplate</title>
      <link>https://morven.life/notes/go_template/</link>
      <pubDate>Fri, 24 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/go_template/</guid>
      <description>随着近几年Restful架构的盛行，前后端分离大行其道，模板渲染也由后端转移到了前端，后端只需要提供资源数据即可，这样导致类似于JSP和PHP的传统服务端模板脚本语言没多少人在用了。但是在Go语言中，模板渲染技术不只局限于服务端HTML页面的渲染，经常用来处理譬如插入特定数据的文本转化等，虽然没有正则表达式那么灵活，但是渲染速度超过正则表达式，而且使用起来也更简单。对于某些云计算的场景十分友好。今天，我们就来详细聊一聊Go Template的技术细节。
运行机制 模板的渲染技术本质上都是一样的，一句话来说明就是字串模板和结构化数据的结合。再详细的讲就是将定义好的模板应用于结构化的数据，使用注解语法引用数据结构中的元素（例如Struct中的特定feild，Map中的key）并显示它们的值。模板在执行过程中遍历数据结构并且设置当前光标（&amp;quot;.&amp;quot;表示当前的作用域）标识当前位置的元素。
类似于Python的jinja，Node的jade等模版引擎，Go语言模板引擎的运行机制也是类似：
 创建模板对象 解析模板字串 加载数据渲染模板  Go模板核心包 Go提供了两个标准库用来处理模板渲染text/template和html/template，它们的接口一致，但处理的模板数据不同。其中text/template用来处理普通文本的模板渲染，而html/template专门用来渲染格式化html字符串。
下面的例子我们使用text/template来处理普通文本模板的渲染：
package main import ( &amp;quot;os&amp;quot; &amp;quot;text/template&amp;quot; ) type Student struct { ID uint Name string } func main() { stu := Student{0, &amp;quot;jason&amp;quot;} tmpl, err := template.New(&amp;quot;test&amp;quot;).Parse(&amp;quot;The name for student {{.ID}} is {{.Name}}&amp;quot;) if err != nil { panic(err) } err = tmpl.Execute(os.Stdout, stu) if err != nil { panic(err) } }  上述代码第4行引入text/template来处理普通文本模板渲染，第14行定义一个模板对象test来解析变量&amp;quot;The name for student {{.</description>
    </item>
    
    <item>
      <title>Docker拾遗</title>
      <link>https://morven.life/notes/the_knowledge_of_docker/</link>
      <pubDate>Wed, 13 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_knowledge_of_docker/</guid>
      <description>Docker是一个划时代的产品，它彻底地释放了计算机虚拟化的威力，极大的提高了应用的部署、测试和分发。虽然我们几乎每天都使用docker，但还是有一些特别容易被忽略却很重要的docker知识，今天，我们就集中起来聊一聊。
Docker与传统虚拟机的区别 经常有人说“docker是一种性能非常好的虚拟机”，这种说法是错误的。Docker相比于传统虚拟机的技术来说更为轻便，具体表现在docker不是在宿主机上虚拟出一套硬件后再运行一个完整的操作系统，然后再在其上运行所需的应用进程，而是docker容器里面的进程直接运行在宿主的内核（Docker会做文件系统、网络互联到进程隔离等等），容器内没有自己的内核，而且也没有进行硬件虚拟。这样一来docker会相对于传统虚拟机来说“体积更轻、跑的更快、同宿主机下可创建的个数更多”。
Docker不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用systemd去启动后台服务，容器内没有后台服务的概念。举个例子，常有人在dockerfile里面这样写：
CMD service nginx start  然后发现容器执行后就立即退出了，甚至在容器内去使用systemctl命令结果却发现根本执行不了。没有区分docker容器和虚拟机的差异，依旧在以传统虚拟机的角度去理解容器。对于docker容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。而使用CMD指令service nginx start，则是以后台守护进程形式启动nginx服务。CMD service nginx start最终会被docker引擎转化为CMD [ &amp;quot;sh&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;service nginx start&amp;quot;]，因此主进程实际上是sh。那么当service nginx start命令结束后，sh也就结束了，sh作为主进程退出了，自然就会令容器退出。
正确的做法是直接执行nginx可执行文件，并且要求以前台形式运行：
CMD [&amp;quot;nginx&amp;quot;, &amp;quot;-g&amp;quot;, &amp;quot;daemon off;&amp;quot;]  慎用docker commit 知道使用docker commit可以在基础镜像层的基础上定制新的镜像。我们知道镜像是多层存储，每一层是在前一层的基础上进行的修改；而容器同样也是多层存储，是在以镜像为基础层，在其基础上加一层作为容器运行时的存储层。
举个例子，我们使用docker commit的定制一个nginx镜像：
$ docker run --name mynginx -d -p 80:80 nginx  上面的命令帮我们启动一个nginx的容器，接着我们就可以使用http://localhost来访问这个容器提供的web服务了，如果没啥意外的话，我们会看到 接着我们访问如下输出：
$ curl http://localhost &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt; &amp;lt;style&amp;gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } &amp;lt;/style&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;h1&amp;gt;Welcome to nginx!</description>
    </item>
    
    <item>
      <title>Webpack使用小结</title>
      <link>https://morven.life/notes/webpack_summary/</link>
      <pubDate>Sun, 20 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/webpack_summary/</guid>
      <description>分而治之是软件工程领域的重要思想，对于复杂度日益增加的前端也同样适用。一般前端团队选择合适的框架之后就要开始考虑开发维护的效率问题。而模块化是目前前端领域比较流行的分而治之手段。 Javascript模块化已经有很多规范和工具，例如CommonJS/AMD/requireJS/CMD/ES6 Module，在上篇文章中有详细的介绍。CSS模块化基本要依靠Less, Sass以及Stylus等于处理器的import/minxin特性实现。而HTML以及HTML模版和其他资源比如图片的模块化怎么去处理呢？ 这也正是webpack要解决的问题之一。严格来说，webpack是一个模块打包工具（module bundler），它既不像requireJS和seaJS这样的模块加载器，也不像grunt和gulp这样优化前端开发流程的构建工具，像是两类工具的集合却又远不止如此。
Webpack是一个模块打包工具，它将JS、CSS、HTML以及图片等都视为模块资源，这些模块资源必然存在某种依赖关系，webpack就是通过静态分析各种模块文件之间的依赖关系，通过不同种类的Loader将所有模块打包成起来。
webpack VS Gulp 严格来说，Gulp与webpack并没有可比性。Gulp应该和Grunt属于同一类工具，能够优化前端工作流程，比如压缩合并JS、CSS ，预编译Typescript、Sass等。也就是说，我们可以根据需要配置插件，就可以将之前需要手动完成的任务自动化。webpack作为模块打包工具，可以和browserify相提并论。两者都是预编译模块化解决方案。相比requireJS、seaJS这类‘在线’模块化方案更加智能。因为是‘预编译’，不需要在浏览器中加载解释器。另外，你可以直接在本地编写JS，不管是 AMD / CMD / ES6 风格的模块化，都编译成浏览器认识的JS。
总之，Gulp只是一个流程构建工具，而webpack、browserify等是模块化解决方案。Gulp也可以配置seaJS、requireJS甚至webpack的插件。
避免多个配置文件 刚开始接触webpack的时候，不管是去浏览GitHub上面star数较多的webpack项目，还是搜索stack overflow上面赞成数较多的回答，发现很多人提倡在一个项目中针对开发和产品发布提供不同的配置文件，比如webpack.dev.config.js和webpack.prod.config.js。看起来很清晰，也可以让新手迅速上手老项目，但仔细研究就会发现，不通环境的配置文件大部分配置项基本相同。这与工程领域一直提倡的DRY（Don&amp;rsquo;t Repeat Yourself）原则相悖，于是就产生了另外一种做法，先生成一个common的webpack.common.config.js，然后再针对不同的环境去继承（其实就是require）common的配置文件。但是不管怎样，其实都是生成多个不同的配置文件。如果换个角度想想，这些配置文件虽然不同，但都遵循着node的逻辑，所以完全可以只维护一个配置文件，然后针对不同的环境传入不同的参数。如果你使用npm，则完全可以在package.json文件中这样写：
&amp;quot;scripts&amp;quot;: { &amp;quot;devs&amp;quot;: &amp;quot;cross-env DEV=1 webpack-dev-server --hot --inline&amp;quot;, &amp;quot;build&amp;quot;: &amp;quot;cross-env PROD=1 rm -rf ./build &amp;amp;&amp;amp; webpack --p&amp;quot; }  其中cross-env是个跨平台的环境变量设置工具，可以允许Unix风格环境变量设置通用在window平台。 这样只维护一个webpack.config.js配置文件，然后在配置文件中处理自定义的参数。怎么处理自定义参数呢？这里我们使用webpack自带插件definePlugin提供魔力变量（magic globals）来处理：
plugins: [ new webpack.DefinePlugin ({ __DEV__: JSON.stringify(JSON.parse(process.env.DEV || &#39;false&#39;)), __PROD__: JSON.stringify(JSON.parse(process.env.PROD || &#39;false&#39;)) }) ]  然后在配置文件的其他地方就可以根据设定的环境变量更有针对性地配置不同插件等。甚至在业务逻辑中也可以这样针对不同环境做针对性地调试，比如在开发环境下可以AJAX可以调试本地mock数据，然后在发布的时候，可以正常访问服务端数据。
if (__DEV__) { // code for dev //.</description>
    </item>
    
    <item>
      <title>Javascript模块化开发</title>
      <link>https://morven.life/notes/developing-modular-javascript/</link>
      <pubDate>Sun, 16 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/developing-modular-javascript/</guid>
      <description>随着互联网时代的到来，前端技术更新速度越来越快。起初只要在script标签中嵌入几行代码就能实现一些基本的用户交互，到现在随着Ajax，jQuery，MVC以及MVVM的发展，Javascript代码量变得日益庞大复杂。 网页越来越像桌面程序，需要一个团队分工协作、进度管理、单元测试等等&amp;hellip;&amp;hellip;开发者不得不使用软件工程的方法，管理网页的业务逻辑。 Javascript模块化开发，已经成为一个迫切的需求。理想情况下，开发者只需要实现核心的业务逻辑，其他都可以加载别人已经写好的模块。 但是，Javascript不是一种模块化编程语言，它不支持&amp;rdquo;类&amp;rdquo;（class），更遑论&amp;rdquo;模块&amp;rdquo;（module）了。直到前不久ES6正式定稿，Javascript才开始正式支持&amp;rdquo;类&amp;rdquo;和&amp;rdquo;模块&amp;rdquo;，但还需要很长时间才能完全投入实用。
什么是模块化 模块是任何大型应用程序架构中不可缺少的一部分，一个模块就是实现特定功能的代码区块或者文件。模块可以使我们清晰地分离和组织项目中的代码单元。在项目开发中，通过移除依赖，松耦合可以使应用程序的可维护性更强。有了模块，开发者就可以更方便地使用别人的代码，想要什么功能，就加载什么模块。模块开发需要遵循一定的规范，否则就会混乱不堪。
Javascript社区做了很多努力，在现有的运行环境中，实现&amp;rdquo;模块&amp;rdquo;的效果。本文总结了当前＂Javascript模块化编程＂的最佳实践，说明如何投入实用。
Javascript模块化基本写法 在第一部分，将讨论基于传统Javascript语法的模块化写法。
原始写法 模块就是实现特定功能的一组方法。 只要把不同的函数（以及记录状态的变量）简单地放在一起，就算是一个模块。
function func1(){ //... } function func2(){ //... }  上面的函数func1()和func2()，组成一个模块。使用的时候，直接调用就行了。 这种做法的缺点很明显：&amp;rdquo;污染&amp;rdquo;了全局变量，无法保证不与其他模块发生变量名冲突，而且模块成员之间看不出直接关系。
对象写法 为了解决上面的缺点，可以把模块写成一个对象，所有的模块成员都放到这个对象里面。
var moduleA = new Object({ _count : 0, func1 : function (){ //... }, func2 : function (){ //... } });  上面的函数func1()和func2(），都封装在moduleA对象里。使用的时候，就是调用这个对象的属性。
moduleA.func1();  但是，这样的写法会暴露所有模块成员，内部状态可以被外部改写。比如，外部代码可以直接改变内部计数器的值。
moduleA._count = 3;  立即执行函数写法 使用&amp;rdquo;立即执行函数&amp;rdquo;（Immediately-Invoked Function Expression，IIFE），可以达到不暴露私有成员的目的。
var moduleA = (function(){ var _count = 0; var func1 = function(){ //.</description>
    </item>
    
    <item>
      <title>SSH协议以及端口转发</title>
      <link>https://morven.life/notes/the_knowledge_of_ssh/</link>
      <pubDate>Thu, 19 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_knowledge_of_ssh/</guid>
      <description>SSH估计是每台Linux机器的标配了。日程工作中程序员在本机写完Code之后，很少在本机上直接部署测试，经常需要通过SSH协议登录到实验室的Linux主机上验证。实际上SSH具备多种功能，不仅仅是远程登录这么简单，今天我们就详细探讨一下SSH协议以及它的高级功能-端口转发。
SSH的原理 SSH是一种网络协议，用于计算机之间的加密登录，也就是说这种登陆是安全的。SSH协议之所以安全，是因为它基于非对称加密。基本的过程可以描述为：
 客户端通过SSH user@remote-host发起登录远程主机的请求 远程主机收到请求之后，将自己的公钥发给客户端 客户端使用这个公钥加密登录密码之后发给远程主机 远程主机使用自己的私钥，解密登陆请求，获得登录密码，如果正确，则建立SSH通道，之后所有客户端和远程主机的数据传输都要加密发送  看似很完美是吗？其实有个问题，如果有人中途拦截了登录请求，将自己伪造的公钥发送给客户端，客户端其实并不能识别这个公钥的可靠性，因为SSH协议并不像HTTPS协议那样，公钥是包含在证书中心CA来颁发的证书之中。所以有攻击者（中间人攻击-Man-in-the-middle-attack）拦截客户端到远程主机的登陆请求，伪造公钥来获取远程主机的登录密码，SSH协议的安全机制就荡然无存了。
说实话，SSH协议本身确实无法阻止这种攻击形式，最终还是依靠终端用户自身来识别并规避风险。
比如，我们在第一次登录某一台远程主机的时候，会得到如下提示：
$ ssh user@remote-host The authenticity of host &#39;10.30.110.230 (10.30.110.230)&#39; can&#39;t be established. ECDSA key fingerprint is SHA256:RIXlybA1rgf4mbnWvLuOMAxGRQQFgfnM2+YbYLT7aQA. Are you sure you want to continue connecting (yes/no)?  这个提示的意思是说无法确定远程主机的真实性，只能得到它的指纹(fingerprint)，需要你确认是否信任这个返回的公钥。这里所说的&amp;rdquo;指纹&amp;rdquo;是RSA公钥的MD5哈希结果。我们知道为了保证RSA私钥的安全性，一般RSA公钥设置基本都不小于1024位，很难直接让终端用户去确认完整的RSA公钥，于是通过MD5哈希函数将之转化为128位的指纹，就很容易识别了。实际上，有很多网络应用程序都是用RSA公钥指纹来让终端用户识别公钥的可靠性。
具体怎么决定是依赖于终端用户了，所以推荐的做法是将远程主机的公钥保存在合适的地方方便核对。这是，如果用户决定接受这个返回的公钥，系统会继续提示：
Warning: Permanently added &#39;10.30.110.230&#39; (RSA) to the list of known hosts.  紧接着就是用户输入密码来登录远程主机。同时远程主机的公钥会被保存在$HOME/.ssh/known_hosts这个文件中，下次登录的时候就不需要用户再次核对指纹了。每个SSH用户都有自己的known_hosts文件，此外系统也有一个这样的文件，通常是/etc/ssh/ssh_known_hosts，保存一些对所有用户都可信赖的远程主机的公钥。
除了使用密码登录，SSH协议还支持公钥登录。这里的公钥不再是远程主机的公钥，而是客户端的RSA公钥。原理很简单：
 用户将客户端的RSA公钥保存在远程主机上 客户端向远程主机发起登录请求 远程主机会向客户端发送一段随机字符串 客户端用自己的RSA私钥加密后再发送给远程主机 远程主机使用保存的的RSA公钥进行解密，如果解密成功则代表客户端是可信的，不需要密码就能确认身份  在客户端生成RSA公私钥对，一般使用ssh-keygen。举例来说，我们要生成2048位RSA密钥对：
$ ssh-keygen -b 2048 -t rsa -f foo_rsa Generating public/private rsa key pair.</description>
    </item>
    
    <item>
      <title>Linux的启动流程</title>
      <link>https://morven.life/notes/the_knowledge_of_linux/</link>
      <pubDate>Tue, 10 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_knowledge_of_linux/</guid>
      <description>和Window等其他操作系统一样，linux的启动也分为两个阶段：引导（boot）和启动（startup）。引导阶段开始于打开电源开关，接下来板载程序BIOS的开始POST上电自检主过程，结束于内核初始化完成。启动阶段接管剩余的工作，直到操作系统初始化完成进入可操作状态，并能够执行用户的功能性任务。
我们不花过多篇幅讲解引导阶段的硬件板载程序加载运行的过程。事实上，由于在板载程序上很多行为基本上固定的，程序员很难介入，所以接下来主要讲讲主板的引导程序如何加载内核程序以及控制权交给linux操作系统之后的各个服务的启动流程。
GRUB引导加载程序 所谓引导程序，一个用于计算机寻找操作系统内核并加载其到内存的智能程序，通常位于硬盘的第一个扇区，并由BIOS载入内存执行。为什么需要引导程序，而不是直接由BIOS加载操作系统？原因是BOIS只会自动加载硬盘的第一个扇区的512字节的内容，而操作系统的大小远远大于这个值，所以才会先加载引导程序，然后通过引导程序加载程序加载操作系统到内存中。
目前，各个Linux发行版主流的引导程序是GRUB(GRand Unified BootLoader)。GRUB的作用有以下几个： - 加载操作系统的内核 - 拥有一个可以让用户选择到底启动哪个系统的的菜单界面 - 可以调用其他的启动引导程序，来实现多系统引导
GRUB1现在已经逐步被弃用，在大多数现代发行版上它已经被GRUB2所替换。GRUB2通过/boot/grub2/grub.cfg进行配置，最终GRUB定位和加载linux内核程序到内存中，并转移控制权到内核程序。
内核程序 内核程序的相关文件位于/boot目录下，这些内核文件均带有前缀vmlinuz。内核文件都是以一种自解压的压缩格式存储以节省空间。在选定的内核加载到内存中并开始执行后，在其进行任何工作之前，内核文件首先必须从压缩格式解压自身。
# ll /boot/ total 152404 drwxr-xr-x 4 root root 4096 Nov 29 15:34 ./ drwxr-xr-x 22 root root 335 Jan 16 12:22 ../ -rw-r--r-- 1 root root 190587 Aug 10 2018 config-3.2.0-3-amd64 -rw-r--r-- 1 root root 190611 Oct 2 12:22 config-3.2.0-4-amd64 drwxr-xr-x 5 root root 4096 Nov 29 15:33 grub/ -rw-r--r-- 1 root root 39413114 Nov 29 15:33 initrd.</description>
    </item>
    
    <item>
      <title>创建私有CA以及颁发SSL证书</title>
      <link>https://morven.life/notes/create_pki_with_openssl/</link>
      <pubDate>Mon, 24 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/create_pki_with_openssl/</guid>
      <description>在上一篇文章深入理解PKI系统的与数字证书中介绍了PKI系统的基本组成以及CA认证中心的主要作用，以及X.509证书基本标准。今天，我们继续应用已经学习的理论知识构建一套自己的PKI/CA数字证书信任体系。
SSL证书生成工具 有以下两种常见的工具来生成RSA公私密钥对:
 Note: 有些情形只需要公私密钥对就够了，不需要数字证书，比如私有的SSH服务。但是对于一些要求身份认证的情形，则需要对公钥进行数字签名形成数字证书。
  ssh-keygen openssl genrsa  实际上ssh-keygen底层也是使用OpenSSL提供的库来生成密钥。
ssh-keygen 举例来说，我们要生成2048位RSA密钥对：
$ ssh-keygen -b 2048 -t rsa -f foo_rsa Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in foo_rsa. Your public key has been saved in foo_rsa.pub. The key fingerprint is: b8:c4:5f:2a:94:fd:b9:56:9d:5b:fd:96:02:5a:7e:b7 user@oasis The key&#39;s randomart image is: +--[ RSA 2048]----+ | | | | | | | .</description>
    </item>
    
    <item>
      <title>深入理解PKI系统的与CA中心</title>
      <link>https://morven.life/notes/the_pki_and_digital_certificate/</link>
      <pubDate>Wed, 12 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_pki_and_digital_certificate/</guid>
      <description>在上一篇文章数字签名与数字证书中介绍了数字签名以及数字证书的一些基础知识以及数字证书的作用，但是并没有提到数字证书的管理，比如数字证书的申请，数字证书的文件格式等知识。这篇文章将继续探讨数字证书的管理知识。
说到数字证书的管理，不得不提到一个词，PKI(Publick Key Infrastructure)，即公钥基础设施，是一种遵循既定标准的密钥管理平台，它能够为所有网络应用提供加密和数字签名等密码服务及所必需的密钥和证书管理体系。简单来说，可以理解为利用之前提到过的供私钥非对称加密技术为应用提供加密和数字签名等密码服务以及与之相关的密钥和证书管理体系。
 PKI既不是一个协议，也不是一个软件，它是一个标准，在这个标准之下发展出的为了实现安全基础服务目的的技术统称为PKI
 PKI的组成 PKI作为一个实施标准，有一系列的组件组成：
 CA(Certificate Authority)中心(证书签发)：是PKI的”核心”，即数字证书的申请及签发机关，CA必须具备权威性的特征，它负责管理PKI结构下的所有用户(包括各种应用程序)的证书，把用户的公钥和用户的其他信息捆绑在一起，在网上验证用户的身份，CA还要负责用户证书的黑名单登记和黑名单发布。
 X.500目录服务器(证书保存)：X.500目录服务器用于&amp;rdquo;发布&amp;rdquo;用户的证书和黑名单信息，用户可通过标准的LDAP协议查询自己或其他人的证书和下载黑名单信息。
 基于SSL(Secure socket layer)的安全web服务器：Secure Socket Layer(SSL)协议最初由Netscape企业发展，现已成为网络用来鉴别网站和网页浏览者身份，以及在浏览器使用者及网页服务器之间进行加密通讯的全球化标准。
 Web(安全通信平台)：Web有Web Client端和Web Server端两部分，分别安装在客户端和服务器端，通过具有高强度密码算法的SSL协议保证客户端和服务器端数据的机密性、完整性、身份验证。
 自开发安全应用系统：自开发安全应用系统是指各行业自开发的各种具体应用系统，例如银行、证券的应用系统等。完整的PKI包括:
1) 认证政策的制定 2) 认证规则 3) 运作制度的制定 4) 所涉及的各方法律关系内容 5) 技术的实现等
  CA 认证中心CA(Certificate Authority)，是一个负责发放和管理数字证书的权威机构，它作为电子商务交易中受信任的第三方，承担公钥体系中公钥的合法性检验的责任。CA为每个使用公开密钥的用户发放一个数字证书，以实现公钥的分发并证明其合法性。作为PKI的核心部分，CA实现了PKI中一些很重要的功能:
 接收验证最终用户数字证书的申请 确定是否接受最终用户数字证书的申请-证书的审批 向申请者颁发、拒绝颁发数字证书-证书的发放 接收、处理最终用户的数字证书更新请求-证书的更新 接收最终用户数字证书的查询、撤销 产生和发布证书废止列表(CRL) 数字证书的归档 密钥归档 历史数据归档  X.509标准 整个PKI体系中有很多格式标准，PKI的标准规定了PKI的设计、实施和运营，规定了PKI各种角色的&amp;rdquo;游戏规则&amp;rdquo;。如果两个PKI应用程序之间要想进行交互，只有相互理解对方的数据含义，交互才能正常进行，标准的作用就是提供了数据语法和语义的共同约定。PKI中最重要的标准，它定义了公钥证书的基本结构。
X.509是定义了公钥证书结构的基本标准，是目前非常通用的证书格式。X.509标准在PKI中起到了举足轻重的作用，PKI由小变大，由原来网络封闭环境到分布式开放环境，X.509起了很大作用，可以说X.509标准是PKI的雏形。PKI是在X.509标准基础上发展起来的。理论上只要为一个网络应用程序创建的证书符合ITU-T X.509国际标准，就可以用于任何其他符合X.509标准的网络应用。对于符合X.509标准的数字证书，必须保证公钥及其所有者(Subject)的姓名是一致的，同时，认证者(Issuer)总是CA或由CA指定的人。X.509数字证书是一些标准字段的集合，这些字段包含有关用户或设备及其相应公钥的信息。X.509标准定义了证书中应该包含哪些信息，并描述了这些信息是如何编码的(即数据格式)，所有的X.509证书包含以下数据：
 版本号(Version)：指出该证书使用了哪种版本的X.509标准（版本1、版本2或是版本3），版本号会影响证书中的一些特定信息，目前的版本为3 序列号(Serial Number)： 标识证书的唯一整数，由证书颁发者分配的本证书的唯一标识符 签名算法标识符： 用于签证书的算法标识，由对象标识符加上相关的参数组成，用于说明本证书所用的数字签名算法。例如，SHA-1和RSA的对象标识符就用来说明该数字签名是利用RSA对SHA-1杂凑加密 认证机构的数字签名：这是使用证书发布者私钥生成的签名，以确保这个证书在发放之后没有被撰改过 认证机构： 证书颁发者的可识别名（DN），是签发该证书的实体唯一的CA的X.500名字。使用该证书意味着信任签发证书的实体。(注意：在某些情况下，比如根或顶级CA证书，发布者自己签发证书) 有效期限(Validity)： 证书起始日期和时间以及终止日期和时间；指明证书在这两个时间内有效 主题信息(Subject)：证书持有人唯一的标识符(或称DN-distinguished name)这个名字在 Internet上应该是唯一的 公钥信息(Public-Key)： 包括证书持有人的公钥、算法(指明密钥属于哪种密码系统)的标识符和其他相关的密钥参数 颁发者唯一标识符(Issuer)：标识符—证书颁发者的唯一标识符，仅在版本2和版本3中有要求，属于可选项  除了以上字段之外，X.</description>
    </item>
    
    <item>
      <title>数字签名与数字证书</title>
      <link>https://morven.life/notes/the_digital_signature_and_digital_certificate/</link>
      <pubDate>Mon, 06 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_digital_signature_and_digital_certificate/</guid>
      <description>在之前的密码学笔记主要是介绍密码学的基础知识，包括两种加密算法的原理，引入在非对称加密算法中数字证书（Digital Certificate）的概念。这篇笔记将继续探讨什么是数字证书，不过在了解它之前，先得知道什么是数字签名（Digital Signature）。
关于数字签名和数字证书的概念，有一篇非常经典的文章，本文的大部分内容来自于那篇文章，喜欢读英文原版的请移步至：http://www.youdzone.com/signature.html
Bob生成了自己的（公钥，私钥）对，将私钥自己保存，并将公钥分发给了他的朋友们：Pat，Susan，Daug，
Susan要给Bob写一封保密的信件，写完后用Bob的公钥加密，就可以达到保密的效果。Bob收到信件之后用自己的私钥来解密，就可以看到信件的内容。这里假设Bob的私钥没有泄露（私钥是十分敏感的信息，一定要注意保管，泄露私钥那么文章里很多假设都不成立），即使信件被别人截获，信件内容也无法解密，也就是说这封信的内容不会有第三个人知道。
Bob给Susan回信，决定采用&amp;rdquo;数字签名&amp;rdquo;：他写完后先用Hash函数，生成信件的摘要（Digest），然后，在使用自己的私钥，对这个摘要进行加密，生成&amp;rdquo;数字签名&amp;rdquo;（Digital Signature）。
Bob将这个数字签名，附在信件里面，一起发给Susan。
Susan收到信件之后，对信件本身使用相同的Hash函数，得到当前信件内容的摘要，同时，取下数字签名，用Bob的公钥解密，得到原始信件的摘要，如果两者相同就说明信件的内容没有被修改过。由此证明，这封信确实是Bob发出的。
但是，更复杂的情况出现了。Daug想欺骗Susan，他伪装成Bob制作了一对（公钥，私钥）对，并将公钥分发给Susan，Susan此时实际保存的是Daug的公钥，但是还以为这是Bob的公钥。因此，Daug就可以冒充Bob，用自己的私钥做成&amp;rdquo;数字签名&amp;rdquo;写信给Susan，而Susan用假的鲍勃公钥进行解密。一切看起来完美无缺？
Susan觉得有些不对劲，因为她并不确定这个公钥是不是真正属于Bob的。于是她想到了一个办法，要求Bob去找&amp;rdquo;证书中心&amp;rdquo;（Certificate Authority，简称CA），为公钥做认证。证书中心用证书中心的私钥，对Bob的公钥和一些相关信息一起加密，生成&amp;rdquo;数字证书&amp;rdquo;（Digital Certificate）。
一旦Bob拿到数字证书以后，就可以放心写信给任何人了。只需要在信件内容的后面附上数字签名的同时，再附上数字证书就行了。
Susan收到信件之后，首先使用用CA的公钥（一般都是公开的）解开数字证书，就可以拿到Bob真实可信的公钥了，然后就能用此公钥解密数字签名进一步验证信件内容是否被篡改过。
由此可见，&amp;rdquo;数字证书&amp;rdquo;就是解决身份认证的问题，就如同现实中我们每一个人都要拥有一张证明个人身份的身份证或驾驶执照一样，以表明我们的身份或某种资格。数字证书是由权威公正的第三方机构即Certificate Authority(CA)中心签发的，确保信息的机密性和防抵赖性。对于一个大型的应用环境，认证中心往往采用一种多层次的分级结构，各级的认证中心类似于各级行政机关，上级认证中心负责签发和管理下级认证中心的证书，最下一级的认证中心直接面向最终用户。</description>
    </item>
    
    <item>
      <title>密码学基础</title>
      <link>https://morven.life/notes/the_basic_of_cryptology/</link>
      <pubDate>Tue, 16 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_basic_of_cryptology/</guid>
      <description>密码学（Cryptography） 密码学是研究编制密码和破译密码的技术科学。研究密码变化的客观规律，应用于编制密码以保守通信秘密的，称为编码学；应用于破译密码以获取通信情报的，称为破译学，总称密码学。 密码是通信双方按约定的法则进行信息特殊变换的一种重要保密手段。依照这些法则，变明文为密文，称为加密变换；变密文为明文，称为脱密变换。密码在早期仅对文字或数码进行加、脱密变换，随着通信技术的发展，对语音、图像、数据等都可实施加、脱密变换。
密码算法 什么是密码算法（Cryptography Algorithm），通常是指加、解密过程所使用的信息变换规则，是用于信息加密和解密的数学函数。对明文进行加密时所采用的规则称作加密算法，而对密文进行解密时所采用的规则称作解密算法。加密算法和解密算法的操作通常都是在一组密钥的控制下进行的。
什么是密钥？密钥（Secret Key）是密码算法中的一个可变参数，通常是一组满足一定条件的随机序列。用于加密算法的叫做加密密钥，用于解密算法的叫做解密密钥，加密密钥和解密密钥可能相同，也可能不相同。
加密算法根据根据密钥的不同分为两类，对称加密算法(Symmetric-key Algorithm)和非对称加密算法(Asymmetric Key Encryption Algorithm)。
对称加密 首先，让我们先从一个情景开始讲起。
比如张三学习比李四好，李四就想在考试的时候让张三“帮助”一下自己，当然，他们俩不可能像我们平常对话一样说，第一题选A，第二题选B等等，为什么？因为监考老师明白他俩在谈论什么，也就是说这种沟通交流方式属于“明文”，所以李四就想：“我需要发明一种，只有我和张三明白的交流方式”，那李四做了什么呢？恩，李四去找张三说：“当我连续咳嗽三声的时候你看我，然后如果我摸了下左耳朵，说明你可以开始给我传答案了，如果没反应，那说明我真的是在咳嗽&amp;hellip;”， 然后，怎么传答案呢？很简单，“你摸左耳朵代表A, 摸右耳朵代表B，左手放下代表C，右手放下代表D”，好了，这就是他们的“算法(规则)”，将信息的一种形式(A,B,C,D)，这里我们称为“明文”，转换成了另一种形式(摸左耳朵，摸右耳朵，放左手，放右手)，这里称为“密文”，经过这种转换，很显然监考老师不会明白这些“密文”，这样，张三和李四就通过“密文”的形式实现了信息的交换。
对称加密算法也叫单钥加密（Private Key Cryptography），加密和解密过程都用同一套密钥。历史上，人类传统的加密方法都是前一种，比如二战期间德军用的Enigma电报密码，莫尔斯电码也可以看作是一种私钥加密方法。
结合前面的例子对应一下，密钥就是“将(A,B,C,D)转换成(摸左耳朵，摸右耳朵，放左手，放右手)”这么一个规则。
 实务上，这组密钥成为在两个或多个成员间的共同秘密，以便维持专属的通讯联系。
 这句话很好理解了吧，密钥是张三和李四间共同的秘密！只有他俩事先知道。 所以，为什么叫对称加密呢，你可以这么理解，一方通过密钥将信息加密后，把密文传给另一方，另一方通过这个相同的密钥将密文解密，转换成可以理解的明文。他们之间的关系如下：
明文 &amp;lt;-&amp;gt; 密钥 &amp;lt;-&amp;gt; 密文  目前常见的对称加密算法有：
DES、3DES、AES、Blowfish、IDEA、RC5、RC6。  非对称加密 非对称加密算法也称为双钥加密（Public Key Cryptography），加密和解密过程用的是两套密钥。非对称加密是一种比对称加密更加优秀的加密算法。对称加密的密钥只有一把，所以密钥的保存变得很重要。一旦密钥泄漏，密码也就被破解。 在非对称加密的情况下，密钥有两把，一把是公开的公钥，还有一把是不公开的私钥。 对称加密的原理如下：
 公钥和私钥是一一对应的关系，有一把公钥就必然有一把与之对应的、独一无二的私钥，反之亦成立。 所有的（公钥, 私钥）对都是不同的。 用公钥可以解开私钥加密的信息，反之亦成立。 同时生成公钥和私钥应该相对比较容易，但是从公钥推算出私钥，应该是很困难或者是不可能的。  在对称加密体系中，公钥用来加密信息，私钥用来数字签名。 比如，李四想给张三发送密文。于是李四开始给张三发消息：
李四： “hi哥们，我想给你发个密文，把你的公钥给我发过来。” 张三： “没问题的，这是我的公钥： d#8yHE8eU#hb*!neb，用这个公钥加密你的信息后给我发过来吧” 李四： “这是我想对你说的话： *&amp;amp;#@uehuu(**#eehu&amp;amp;$##bfeu&amp;amp;&amp;amp;”  为什么公开问公钥？非对称解密算法的强大之处就在这里！公钥可以随意分发，所以即使第三方截取了，也只是知道该公钥而已，但是要是想解密使用该公钥加密的密文！只有一个人可以办得到！就是张三！ 为什么？李四使用张三的公钥加密的信息，只有张三的公钥所对应的私钥，这里就是“张三私钥”，该私钥才可以解密！所以，没有张三私钥的第三方即时截取了这些密文，也破解不了！或者更严格的说在有限时间内比如说几千年内是暴力破解不出的！
非对称加密算法，首先要有一对key，一个被称为私钥（Private Key），一个成为公钥（Public Key），然后可以把公钥分发给想给你传密文的用户，然后用户使用该公钥加密过得密文，只有使用私钥才能解密，也就是说，只要保存好你的私钥，就能确保别人想给你发的密文不被破解。正因为，这种加密是单向的，所以被称为非对称加密算法。
这种加密算法应用非常广泛，SSH, HTTPS, TLS，电子证书，电子签名，电子身份证等等。
因为任何人都可以生成自己的（公钥，私钥）对，所以为了防止有人散布伪造的公钥骗取信任，就需要一个可靠的第三方机构来生成经过认证的（公钥，私钥）对。这就是数字证书的作用了，接下来的文章将会继续探讨什么是数字签名以及数字证书。</description>
    </item>
    
    <item>
      <title>字符编码的前世今生</title>
      <link>https://morven.life/notes/the_character_encoding/</link>
      <pubDate>Sun, 12 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_character_encoding/</guid>
      <description>字符编码问题看似无关紧要，常常被忽略，但是对字符编码知识没有一个完整系统的认识，实际编码过程中会让我们吃尽苦头。今天，我们就来看一看字符编码的前世今生。
ASCII-一切的起源 字符编码主要是解决如何使用计算机的方式来表达特定的字符，但是有计算机基础理论知识的人都知道，计算机内部所有的数据都是基于二进制，每个二进制位（bit）有0和1两种状态，我们可以组合多个二进位来表达更大的数值，例如八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。这就是说，我们可以一个字节来映射用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从00000000到11111111，这样就建立了最初的计算机数值到自然语言字符最基本的映射关系。上个世纪60年代，美国国家标准协会ANSI制定了一个标准，规定了常用字符的集合以及每个字符对应的编号，这就是ASCII字符集（Character Set），也称ASCII码。ASCII码规定了英语字符与二进制位之间的对应关系。
ASCII码一共规定了128个字符的编码（包括32个不能打印出来的控制符号），比如空格SPACE是32（二进制表示为00100000），大写的字母A是65（二进制表示为01000001）。这128个符号只需要占用了一个字节的后面7位，最前面的一位统一规定为0。
按照ASCII字符集编码和解码就是简单的查表过程。例如将字符序列编码为二进制流写入存储设备，只需要在ASCII字符集中依次找到字符对应的字节，然后直接将该字节写入存储设备即可，解码二进制流就是相反的过程。
各种OEM编码的衍生 当计算机发展起来的时候，人们逐渐发现，ASCII字符集里的128个字符不能满足他们的需求。在英语国家，128个字符编码足矣，但是对于非英语国家，人们无法在ASCII字符集中找到他们的基本字符。比如，在法语中，字母上方有注音符号，它就无法用ASCII码表示。于是有些人就在想，ASCII字符只是使用了一个字节的前128个变换，后面的128位完全可以利用起来，于是一些一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。
但是，这里又出现了新的问题。不同的国家有不同的字母，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。比如，130在法语编码中代表了é，在希伯来语编码中却代表了字母Gimel (ג)，在俄语编码中又会代表另一个符号。不同的OEM字符集导致人们无法跨机器传播交流各种信息。例如甲发了一封简历résumés给乙，结果乙看到的却是rגsumגs，因为é字符在甲机器上的OEM字符集中对应的字节是0×82，而在乙的机器上，由于使用的OEM字符集不同，对0×82字节解码后得到的字符却是ג。
但是尽管出现了不同的OEM编码，所有这些编码方式中，0--127表示的符号是一样的，不一样的只是128--255的这一段代表的字符。
至于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是GB2312，使用两个字节表示一个汉字，所以理论上最多可以表示256 x 256 = 65536个符号。
 Note: 中文编码的问题很复杂，这篇笔记就深入讨论，但需要指出的是虽然都是用多个字节表示一个符号，但是GB类的汉字编码与后文的Unicode和UTF-8是毫无关系的。
 从ANSI标准到国家标准再到ISO标准 不同ASCII衍生字符集的出现，让文档交流变得非常困难，因此各种组织都陆续进行了标准化流程。例如美国ANSI组织制定了ANSI标准字符编码，ISO组织制定的各种ISO标准字符编码，还有各国也会制定一些国家标准字符集，例如中国的GBK，GB2312和GB18030。
每台计算机的操作系统都会预装这些标准的字符集还有平台专用的字符集，这样只要使用标准字符集编写文档就可以达到很高的通用性。例如用GB2312字符集编写的文档，在中国大陆内的任何机器上都能正确显示。当然，也可以在一台计算机上阅读多个不同国家语言的文档，但是前提是计算机必须得安装该文档使用的字符集。
Unocode的出现 虽然通过使用不同字符集，我们可以在一台计算机上查阅不同语言的文档，但是仍然无法解决一个问题：在一份文档中显示所有字符。那时的人们就在想，如果有一种编码，能够映射世界上所有的语言符号，每一个符号都给予一个无二义的编码，那么乱码问题就会消失。这就是Unicode字符集，就像它的名字都表示的，这是一种所有符号的编码。
Unicode字符集包括了目前人类使用的所有字符，当然是一个很大的集合，现在的规模可以容纳100多万个符号。每个符号的编码都不一样，比如，U+0639表示阿拉伯字母Ain，U+0041表示英语的大写字母A，U+4E25表示汉字严。Unicode字符集将所有字符按照使用上的频繁度划分为17个层面（Plane），每个层面上有2^16=65536个字符空间。具体的符号对应表，可以查询unicode.org，或者专门的汉字对应表。
Unicode的问题 有了Unicode之后，人们常会问一个问题？
 Unicode是需要两个字节存储吗？
 其实Unicode只是定义了一个庞大的、全球通用的字符集，并为每个字符规定了唯一确定的二进制代码，却没有规定这个二进制代码应该如何存储。
例如，汉字严的Unicode是十六进制数#4E25，转换成二进制数足足有15位（100111000100101），也就是说，这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。
这样的话就会有两个严重的问题，第一个问题是，如何才能区别Unicode和ASCII？计算机无法知道三个字节是表示一个字符，还是分别表示三个字符。第二个问题是，英文字母只用一个字节表示就够了，但是基于Unicode的规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。
它们造成的结果是：
 出现了Unicode的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示Unicode。 Unicode在很长一段时间内无法推广，直到互联网的出现。  UTF-8 随着互联网的普及，人们强烈要求出现一种统一的Unicode的编码方式。UTF-8就是在互联网上使用最广的一种Unicode的编码实现方式。其他实现方式还包括UTF-16（字符用两个字节或四个字节表示）和UTF-32（字符用四个字节表示），不过在互联网上基本不用。
由于UCS-2/UTF-16对于ASCII字符使用两个字节进行编码，存储和处理效率相对低下，并且由于ASCII字符经过UTF-16编码后得到的两个字节，高字节始终是0×00，很多C语言的函数都将此字节视为字符串末尾从而导致无法正确解析文本。因此UTF-16刚推出的时候遭到很多西方国家的抵触，大大影响了Unicode的推行。后来聪明的人们发明了UTF-8编码，解决了这个问题。
 Note：一定要记住，UTF-8是Unicode的编码实现方式之一。
 UTF-8最大的一个特点，就是它是一种“变长”的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。
UTF-8的编码规则简单实用：
 对于单字节的符号，字节的第一位设为0，后面7位为这个符号的Unicode码。因此对于英文字母，UTF-8编码和ASCII编码是完全相同的 对于n字节的符号（n &amp;gt; 1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的Unicode码  下表总结了编码规则，字母x表示可用编码的位：
   Unicode符号范围 UTF-8编码方式     十六进制表示 二进制表示   0000 0000-0000 007F 0xxxxxxx   0000 0080-0000 07FF 110xxxxx 10xxxxxx   0000 0800-0000 FFFF 1110xxxx 10xxxxxx 10xxxxxx   0001 0000-0010 FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx    基于上表，解读UTF-8编码就非常简单。如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。</description>
    </item>
    
  </channel>
</rss>