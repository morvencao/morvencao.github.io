<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notes on Morven&#39;s Life</title>
    <link>https://morven.life/notes/</link>
    <description>Recent content in Notes on Morven&#39;s Life</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Jan 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://morven.life/notes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>容器网络(一)</title>
      <link>https://morven.life/notes/networking-4-docker-summary/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/networking-4-docker-summary/</guid>
      <description>所谓容器网络需要结局的两大核心问题是：
 容器IP地址的管理 容器之间的相互通信  其中，容器IP地址的管理包括容器IP地址的分配与回收，而容器之间的相互通信包括同一主机容器之间和跨主机容器之间通信两种场景。这两个问题也不能完全分开来看，因为不同的解决方案往往要同时考虑以上两点。容器网络的发展已经相对成熟，这篇笔记先对主流容器网络模型做一些概述，然后将进一步对典型的容器网络模型展开实践。
CNM vs CNI 关于容器网络，Docker与Kubernetes分别提出了不同的规范标准：
 Docker采用的CNM(Container Network Model) Kunernetes支持的CNI模型(Container Network Interface)  CNM基于libnetwork，是Docker内置的模型规范，它的总体架构如下图所示：
可以看到，CNM规范主要定义了以下三个组件：
 Sandbox: 每个Sandbox包一个容器网络栈(network stack)的配置：容器的网口、路由表和DNS设置等，Sanbox可以通过Linux网络命名空间netns来实现 Endpoint: 每个Sandbox通过Endpoint加入到一个Network里，Endpoint可以通过Linux虚拟网络设备veth对来实现 Network: 一组能相互直接通信的Endpoint，Network可以通过Linux网桥设备bridge，VLAN等实现  可以看到，底层实现原理还是我们之前介绍过的Linux虚拟网络设备，网络命名空间等。但是，为什么Kubernetes没有采用CNM规范标准；而是选择CNI，感兴趣的话可以去看看Kubernetes的文章Why Kubernetes doesn’t use libnetwork，总的来说，不使用CNM最关键的一点是，是因为Kubernetes考虑到CNM在一定程度上和container runtime耦合度太高，因此以Kubernetes为领导的其他一些组织开始制定新的CNI规范。CNI并不是Docker原生支持的，它是为容器技术设计的通用型网络接口，因此CNI接口可以很容易地从高层向底层调用，但从底层到高层却不是很方便，所以一些常见的CNI插件很难在Docker层面激活。但是这两个模型全都支持插件化，也就是说我们每个人都可以按照这两套网络规范来编写自己的具体网络实现。
我们省去这两套规范的具体介绍，直接从要解决的网络问题出发，来看看主流的容器网络实现原理。
技术术语 在开始之前，我们总结一些在容器网络的介绍文章里面看到各种技术术语：
 IPAM: IP Address Management，即IP地址管理。IPAM并不是容器时代特有的词汇，传统的标准网络协议比如DHCP其实也是一种IPAM，负责从MAC地址分发IP地址；但是到了容器时代我们提到IPAM，我们特指为每一个容器实例分配和回收IP地址，保证一个集群里面的所有容器都分配全局唯一的IP地址；主流的做法包括：基于CIDR的IP地址段分配地或精确为每一个容器分配IP。 Overlay：在容器时代，就是在主机现有二层（数据链路层）或三层（IP网络层）基础之上再构建起来一个独立的网络，这个overlay网络通常会有自己独立的IP地址空间、交换或者路由的实现。 IPIP: 一种基于Linux网络设备TUN实现的隧道协议，允许将三层（IP）网络包封装在另外一个三层网络包之发送和接收，详情请看之前IPIP隧道的介绍笔记。 IPSec: 跟IPIP隧道协议类似，是一个点对点的一个加密通信协议，一般会用到Overlay网络的数据隧道里。 VXLAN：最主要是解决VLAN支持虚拟网络数量（4096）过少的问题而由VMware、Cisco、RedHat等联合提出的解决方案。VXLAN可以支持在一个VPC(Virtual Private Cloud)划分多达1600万个虚拟网络。 BGP: 主干网自治网络的路由协议，当代的互联网由很多小的AS自治网络(Autonomous system)构成，自治网络之间的三层路由是由BGP实现的，简单来说，通过BGP协议AS告诉其他AS自己子网里都包括哪些IP地址段，自己的AS编号以及一些其他的信息。 SDN: Software-Defined Networking，一种广义的概念，通过软件方式快速配置网络，往往包括一个中央控制层来集中配置底层基础网络设施。  host网络 不管是对外暴露容器内的服务还是容器之间的跨主机通信，我们能想到的最直观的解决方案就是直接使用宿主机host网络，这时，容器完全复用复用宿主机的网络设备以及协议栈，容器的IP就是主机的IP，这样，只要宿主机主机能通信，容器也就自然能通信。但是这样，为了暴露容器服务，每个容器需要占用宿主机上的一个端口，通过这个端口和外界通信。所以，就需要手动维护端口的分配，不要使不同的容器服务运行在一个端口上，正因为如此，这种容器网络模型很难被推广到生产环境。
docker原生支持的网络模式可以通过docker network ls来看：
# docker network ls NETWORK ID NAME DRIVER SCOPE f559b082c95f bridge bridge local 5f11ccbbf488 host host local 97aedfe8792d none null local  可以看到三种网络模型，在创建容器的时候可以通过--network来指定要使用的模型。其中bridge是默认的网络模型，我们后面将会模拟实现bridge模型；nono不创建任何网络，host网络模型是我们即将要验证的，它不会创建新的netns网络命名空间。</description>
    </item>
    
    <item>
      <title>IPIP隧道实践</title>
      <link>https://morven.life/notes/networking-3-ipip/</link>
      <pubDate>Wed, 29 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/networking-3-ipip/</guid>
      <description>上一篇笔记中，我们在介绍TUN/TAP网络设备的时候介绍了一种典型的VPN实现拓扑，但是并没有实践TUN/TAP虚拟网络设备具体在linux中怎么发挥实际的功能。这篇笔记我们就来看看在云计算领域中一种非常典型的IPIP隧道试图和通过TUN设备来实现。
IPIP隧道 上一篇笔记中我们也提到了，TUN设备能将三层（IP）网络包封装在另外一个三层网络包之中，看起来通过TUN设备发送出来的数据包会像会这样：
MAC: xx:xx:xx:xx:xx:xx IP Header: &amp;lt;new destination IP&amp;gt; IP Body: IP: &amp;lt;original destination IP&amp;gt; TCP: stuff HTTP: stuff  这就是典型的IPIP隧道数据包的结构。Linux原生支持好几种不同的IPIP隧道类型，但都依赖于TUN虚拟网络设备，我们可以通过命令ip tunnel help来查看IPIP隧道的相关类型以及操作：
# ip tunnel help Usage: ip tunnel { add | change | del | show | prl | 6rd } [ NAME ] [ mode { ipip | gre | sit | isatap | vti } ] [ remote ADDR ] [ local ADDR ] [ [i|o]seq ] [ [i|o]key KEY ] [ [i|o]csum ] [ prl-default ADDR ] [ prl-nodefault ADDR ] [ prl-delete ADDR ] [ 6rd-prefix ADDR ] [ 6rd-relay_prefix ADDR ] [ 6rd-reset ] [ ttl TTL ] [ tos TOS ] [ [no]pmtudisc ] [ dev PHYS_DEV ] Where: NAME := STRING ADDR := { IP_ADDRESS | any } TOS := { STRING | 00.</description>
    </item>
    
    <item>
      <title>Linux虚拟网络设备</title>
      <link>https://morven.life/notes/networking-2-linux-virtual-devices/</link>
      <pubDate>Tue, 28 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/networking-2-linux-virtual-devices/</guid>
      <description>随着容器逐步取代虚拟机，成为现在云基础架构的标准，这些容器的网络管理模块都离不开Linux虚拟网络设备。事实上，了解常用的Linux虚拟网络设备对于我们理解容器网络以及其他依赖于容器的基础架构网络实现都大有裨益。现在开始，我们就来看看常见的Linux虚拟网络设备有哪些以及它们的使用场景。
虚拟网络设备 通过上一篇笔记我们也知道，网络设备的驱动程序并不直接与内核中的协议栈交互，而是通过内核的网络设备管理模块。这样做的好处是，驱动程序不需要了解协议栈的细节，协议栈也不需要针对特定驱动处理数据包。
对于内核网络设备管理模块来说，虚拟设备和物理设备没有区别，都是网络设备，都能配置IP，甚至从逻辑上来看，虚拟网络设备和物理网络设备并没有什么区别，它们都类似于管道，从任意一端接收到的数据将从另外一端发送出去。比如物理网卡的两端分别是协议栈于外面的物理网络，从外面物理网络接收到的数据包会转发给协议栈，相反，应用程序通过协议栈发送过来的数据包会通过物理网卡发送到外面的物理网络。但是对于具体将数据包发送到哪里，怎么发送，不同的网络设备有不同的驱动实现，与内核设备管理模块以及协议栈没什么关系。
总的来说，虚拟网络设备与物理网络设备没有什么区别，它们的一端连接着内核协议栈，而另一端的行为是什么取决于不同虚拟网络设备的驱动实现。
TUN/TAP TUN/TAP虚拟网络设备一端连着协议栈，另外一端不是物理网络，而是另外一个处于用户空间的应用程序。也就是说，协议栈发给TUN/TAP的数据包能被这个应用程序读取到，当然应用程序能直接向TUN/TAP发送数据包。
一个典型的TUN/TAP的例子如下图所示：
上图中我们配置了一个物理网卡，IP为18.12.0.92，而tun0为一个TUN/TAP设备，IP配置为10.0.0.12。数据包的流向为：
 应用程序A通过socket A发送了一个数据包，假设这个数据包的目的IP地址是10.0.0.22 socket A将这个数据包丢给协议栈 协议栈根据本地路由规则和数据包的目的IP，将数据包由给tun0设备发送出去 tun0收到数据包之后，将数据包转发给给了用户空间的应用程序B 应用程序B收到数据包之后构造一个新的数据包，将原来的数据包嵌入在新的数据包（IPIP包）中，最后通过socket B将数据包转发出去 &amp;gt; Note: 新数据包的源地址变成了eth0的地址，而目的IP地址则变成了另外一个地址18.13.0.91. socket B将数据包发给协议栈 协议栈根据本地路由规则和数据包的目的IP，决定将这个数据包要通过eth0发送出去，于是将数据包转发给eth0 eth0通过物理网络将数据包发送出去  我们看到发送给10.0.0.22的网络数据包通过在用户空间的应用程序B，利用18.12.0.92发到远端网络的18.13.0.91，网络包到达18.13.0.91后，读取里面的原始数据包，读取里面的原始数据包，再转发给本地的10.0.0.22。这就是VPN的基本原理。
使用TUN/TAP设备我们有机会将协议栈中的部分数据包转发给用户空间的应用程序，让应用程序处理数据包。常用的使用场景包括数据压缩，加密等功能。
 Note: TUN和TAP设备的区别在于，TUN设备是一个虚拟的端到端IP层设备，也就是说用户空间的应用程序通过TUN设备只能读写IP网络数据包（三层），而TAP设备是一个虚拟的链路层设备，通过TAP设备能读写链路层数据包（二层）。在使用ip命令创建设备的时候使用--dev tun和--dev tap来区分。
 veth veth虚拟网络设备一端连着协议栈，另外一端不是物理网络，而是另一个veth设备，成对的veth设备中一个数据包发送出去后会直接到另一个veth设备上去。每个veth设备都可以被配置IP地址，并参与三层IP网络路由过程。
下面就是一个典型的veth设备对的例子：
我们配置物理网卡eth0的IP为12.124.10.11， 而成对出现的veth设备分别为veth0和veth1，它们的IP分别是20.1.0.10和20.1.0.11。
# ip link add veth0 type veth peer name veth1 # ip addr add 20.1.0.10/24 dev veth0 # ip addr add 20.1.0.11/24 dev veth1 # ip link set veth0 up # ip link set veth1 up  然后尝试从veth0设备ping另一个设备veth1:</description>
    </item>
    
    <item>
      <title>Linux数据包的接收与发送过程</title>
      <link>https://morven.life/notes/networking-1-linux-pkg-snd-rcv/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/networking-1-linux-pkg-snd-rcv/</guid>
      <description>早在农历新年之前，就构思着将近半年重拾的网络基础整理成成一个系列，正好赶上武汉疫情在春节假期爆发，闲来无事，于是开始这一系列的笔记。
我的整体思路是：
 第一篇笔记会简单介绍Linux网络数据包接收和发送过程，但不涉及TCP/IP协议栈的细节知识，如果有需要了解这些基础知识的读者，我推荐去阅读阮一峰老师的互联网协议的系列文章。 接下来，我会总结常用的Linux虚拟设备，同时会结合Linux自带的新网络工具包iproute2来操作这些常用的网络设备。 有了前面的基础知识，我们再来了解几种常用的容器网络实现远离。 最后，我们深入探讨一下K8s平台中主流的网络实现。  其实，严格上来说，这种学习思路其实很“急功近利”，但是，对于不太了解网络基础知识和Linux内核原理的人来说，这反而是一种很有效的学习方式。但是，私以为学习过程不只应该由浅入深，更应该螺旋向前迭代，温故而知新，才能获益良多。
数据包的接收过程 废话不多说，我们先开始第一篇笔记的内容。
为了简化起见，我们以一个UDP数据包在物理网卡上处理流程来介绍Linux网络数据包的接收和发送过程，我会尽量忽略一些不相关的细节。
从网卡到内存 我们知道，每个网络设备（网卡）需要有驱动才能工作，驱动需要在内核启动时加载到内核中才能工作。事实上，从逻辑上看，驱动是负责衔接网络设备和内核网络栈的中间模块，每当网络设备接收到新的数据包时，就会触发中断，而对应的中断处理程序正是加载到内核中的驱动程序。
下面这张图详细的展示了数据包如何从网络设备进入内存，并被处于内核中的驱动程序和网络栈处理的：
 数据包进入物理网卡。如果目的地址不是该网络设备，且该来网络设备没有开启混杂模式，该包会被网络设备丢弃。 物理网卡将数据包通过DMA的方式写入到指定的内存地址，该地址由网卡驱动分配并初始化。 物理网卡通过硬件中断（IRQ）通知CPU，有新的数据包到达物理网卡需要处理。 CPU根据中断表，调用已经注册的中断函数，这个中断函数会调到驱动程序（NIC Driver）中相应的函数 驱动先禁用网卡的中断，表示驱动程序已经知道内存中有数据了，告诉物理网卡下次再收到数据包直接写内存就可以了，不要再通知CPU了，这样可以提高效率，避免CPU不停的被中断。 启动软中断继续处理数据包。这样的原因是硬中断处理程序执行的过程中不能被中断，所以如果它执行时间过长，会导致CPU没法响应其它硬件的中断，于是内核引入软中断，这样可以将硬中断处理函数中耗时的部分移到软中断处理函数里面来慢慢处理。  内核处理数据包 上一步中网络设备驱动程序会通过软触发内核网络模块中的软中断处理函数，内核处理数据包的流程如下图所示：
 对于第6步中驱动发出的软中断，内核中的ksoftirqd进程会调用网络模块的相应软中断所对应的处理函数，这里其实就是调用net_rx_action函数。 接下来net_rx_action调用网卡驱动里的poll函数来一个个地处理数据包。 而poll函数会让驱动会读取网卡写到内存中的数据包。事实上，内存中数据包的格式只有驱动知道。 驱动程序将内存中的数据包转换成内核网络模块能识别的skb(socket buffer)格式，然后调用napi_gro_receive函数 napi_gro_receive会处理GRO相关的内容，也就是将可以合并的数据包进行合并，这样就只需要调用一次协议栈。然后判断是否开启了RPS，如果开启了，将会调用enqueue_to_backlog。 enqueue_to_backlog函数会将数据包放入input_pkt_queue结构体中，然后返回。 &amp;gt; Note: 如果input_pkt_queue满了的话，该数据包将会被丢弃，这个queue的大小可以通过net.core.netdev_max_backlog来配置 接下来CPU会在软中断上下文中处理自己input_pkt_queue里的网络数据（调用__netif_receive_skb_core函数） 如果没开启RPS，napi_gro_receive会直接调用__netif_receive_skb_core函数。 紧接着CPU会根据是不是有AF_PACKET类型的socket（原始套接字），如果有的话，拷贝一份数据给它(tcpdump抓包就是抓的这里的包)。 将数据包交给内核协议栈处理。 当内存中的所有数据包被处理完成后（poll函数执行完成），重新启用网卡的硬中断，这样下次网卡再收到数据的时候就会通知CPU。  内核协议栈 内核网络协议栈此时接收到的数据包其实是三层(IP网络层)数据包，因此，数据包首先会进入到IP网络层层，然后进入传输层处理。
IP网络层  ip_rcv: ip_rcv函数是IP网络层处理模块的入口函数，该函数首先判断属否需要丢弃该数据包（目的mac地址不是当前网卡，并且网卡设置了混杂模式），如果需要进一步处理就然后调用注册在netfilter中的NF_INET_PRE_ROUTING这条链上的处理函数。 NF_INET_PRE_ROUTING: netfilter放在协议栈中的钩子函数，可以通过iptables来注入一些数据包处理函数，用来修改或者丢弃数据包，如果数据包没被丢弃，将继续往下走。 &amp;gt; NF_INET_PRE_ROUTING等netfilter链上的处理逻辑可以通iptables来设置，详情请移步: https://morven.life/notes/the_knowledge_of_iptables/ routing: 进行路由处理，如果是目的IP不是本地IP，且没有开启ip forward功能，那么数据包将被丢弃，如果开启了ip forward功能，那将进入ip_forward函数。 ip_forward: 该函数会先调用netfilter注册的NF_INET_FORWARD链上的相关函数，如果数据包没有被丢弃，那么将继续往后调用dst_output_sk函数。 dst_output_sk: 该函数会调用IP网络层的相应函数将该数据包发送出去，这一步将会在下一章节发送数据包中详细介绍。 ip_local_deliver: 如果上面路由处理发现发现目的IP是本地IP，那么将会调用ip_local_deliver函数，该函数先调用NF_INET_LOCAL_IN链上的相关函数，如果通过，数据包将会向下发送到UDP层。  传输层  udp_rcv: 该函数是UDP处理层模块的入口函数，它首先调用__udp4_lib_lookup_skb函数，根据目的IP和端口找对应的socket，如果没有找到相应的socket，那么该数据包将会被丢弃，否则继续。 sock_queue_rcv_skb: 该函数一是负责检查这个socket的receive buffer是不是满了，如果满了的话就丢弃该数据包；二是调用sk_filter看这个包是否是满足条件的包，如果当前socket上设置了filter，且该包不满足条件的话，这个数据包也将被丢弃。 __skb_queue_tail: 该函数将数据包放入socket接收队列的末尾。 sk_data_ready: 通知socket数据包已经准备好。 调用完sk_data_ready之后，一个数据包处理完成，等待应用层程序来读取。   Note: 上面所述的所有执行过程都在软中断的上下文中执行。</description>
    </item>
    
    <item>
      <title>Docker知识点拾遗</title>
      <link>https://morven.life/notes/the_knowledge_of_docker/</link>
      <pubDate>Tue, 13 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_knowledge_of_docker/</guid>
      <description>Docker是一个划时代的产品，它彻底地释放了计算机虚拟化的威力，极大的提高了应用的部署、测试和分发。虽然我们几乎每天都使用docker，但还是有一些特别容易被忽略却很重要的docker知识，今天，我们就集中起来聊一聊。
Docker与传统虚拟机的区别 经常有人说“docker是一种性能非常好的虚拟机”，这种说法是错误的。Docker相比于传统虚拟机的技术来说更为轻便，具体表现在docker不是在宿主机上虚拟出一套硬件后再运行一个完整的操作系统，然后再在其上运行所需的应用进程，而是docker容器里面的进程直接运行在宿主的内核（Docker会做文件系统、网络互联到进程隔离等等），容器内没有自己的内核，而且也没有进行硬件虚拟。这样一来docker会相对于传统虚拟机来说“体积更轻、跑的更快、同宿主机下可创建的个数更多”。
Docker不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用systemd去启动后台服务，容器内没有后台服务的概念。举个例子，常有人在dockerfile里面这样写：
CMD service nginx start  然后发现容器执行后就立即退出了，甚至在容器内去使用systemctl命令结果却发现根本执行不了。没有区分docker容器和虚拟机的差异，依旧在以传统虚拟机的角度去理解容器。对于docker容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。而使用CMD指令service nginx start，则是以后台守护进程形式启动nginx服务。CMD service nginx start最终会被docker引擎转化为CMD [ &amp;quot;sh&amp;quot;, &amp;quot;-c&amp;quot;, &amp;quot;service nginx start&amp;quot;]，因此主进程实际上是sh。那么当service nginx start命令结束后，sh也就结束了，sh作为主进程退出了，自然就会令容器退出。
正确的做法是直接执行nginx可执行文件，并且要求以前台形式运行：
CMD [&amp;quot;nginx&amp;quot;, &amp;quot;-g&amp;quot;, &amp;quot;daemon off;&amp;quot;]  慎用docker commit 知道使用docker commit可以在基础镜像层的基础上定制新的镜像。我们知道镜像是多层存储，每一层是在前一层的基础上进行的修改；而容器同样也是多层存储，是在以镜像为基础层，在其基础上加一层作为容器运行时的存储层。
举个例子，我们使用docker commit的定制一个nginx镜像：
$ docker run --name mynginx -d -p 80:80 nginx  上面的命令帮我们启动一个nginx的容器，接着我们就可以使用http://localhost来访问这个容器提供的web服务了，如果没啥意外的话，我们会看到 接着我们访问如下输出：
$ curl http://localhost &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt; &amp;lt;style&amp;gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } &amp;lt;/style&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;h1&amp;gt;Welcome to nginx!</description>
    </item>
    
    <item>
      <title>5分钟系列 -「Go Template」</title>
      <link>https://morven.life/notes/the_go_template/</link>
      <pubDate>Fri, 24 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_go_template/</guid>
      <description>随着近几年Restful架构的盛行，前后端分离大行其道，模板渲染也由后端转移到了前端，后端只需要提供资源数据即可，这样导致类似于JSP和PHP的传统服务端模板脚本语言几乎问人问津了。但是在Go语言中，模板渲染技术不只局限于服务端标记语言（如HTML页面）的渲染，事实上，GO语言经常使用模版语言来处理譬如插入特定数据的文本转化等，虽然没有正则表达式那么灵活，但是渲染效率远优于正则表达式，而且使用起来也更简单。对于某些云计算的场景十分友好。今天，我们就来详细聊一聊Go Template的技术细节。
运行机制 模板的渲染技术本质上都是一样的，一句话来说明就是字串模板和结构化数据的结合，再详细地讲就是将定义好的模板应用于结构化的数据，使用注解语法引用数据结构中的元素（例如Struct中的特定feild，Map中的key）并显示它们的值。模板在执行过程中遍历数据结构并且设置当前光标（&amp;quot;.&amp;quot;表示当前的作用域）标识当前位置的元素。
类似于Python的jinja，Node的jade等模版引擎，Go语言模板引擎的运行机制也是类似：
 创建模板对象 解析模板字串 加载数据渲染模板  Go模板核心包 Go提供了两个标准库用来处理模板渲染text/template和html/template，它们的接口几乎一摸一样，但处理的模板数据不同。其中text/template用来处理普通文本的模板渲染，而html/template专门用来渲染格式化html字符串。
下面的例子我们使用text/template来处理普通文本模板的渲染：
package main import ( &amp;quot;os&amp;quot; &amp;quot;text/template&amp;quot; ) type Student struct { ID uint Name string } func main() { stu := Student{0, &amp;quot;jason&amp;quot;} tmpl, err := template.New(&amp;quot;test&amp;quot;).Parse(&amp;quot;The name for student {{.ID}} is {{.Name}}&amp;quot;) if err != nil { panic(err) } err = tmpl.Execute(os.Stdout, stu) if err != nil { panic(err) } }  上述代码第4行引入text/template来处理普通文本模板渲染，第14行定义一个模板对象test来解析变量&amp;quot;The name for student {{.</description>
    </item>
    
    <item>
      <title>5分钟系列 -「Go Context」</title>
      <link>https://morven.life/notes/the_go_context/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_go_context/</guid>
      <description>从go1.7开始，正式将context(golang.org/x/net/context)，即“上下文”包引入官方标准库。事实上，我们经常见到它，不论是在一般的服务器代码还是在复杂的并发处理程序中，它都起到很重要的作用。今天，我们就来深入研究一下它的实现以及最佳实践。
官方文档对于context包的解释是：
 Package context defines the Context type, which carries deadlines, cancelation signals, and other request-scoped values across API boundaries and between processes.
 简单来说，context包是专门用来简化处理针对单个请求的多个goroutine与请求截止时间、取消信号以及请求域的数据等相关操作。一个简单的例子是在典型的go服务器程序中，每个网络请求都需要创建单独的goroutine进行处理，这些goroutine有可能涉及多个API的调用，进而可能会开启其他的goroutine；由于这些goroutine都是在处理同一个网络请求，所以它们往往需要访问一些共享的资源，比如用户认证token、请求截止时间等；而且如果请求超时或者被取消后，所有的goroutine都应该马上退出并且释放相关的资源。使用context，即“上下文”，可以让go开发者方便地实现这些多个goroutine之间的交互操作，跟踪并控制这些goroutine，并传递request相关的数据、取消goroutine的signal或截止日期等。
Context结构 context包中核心的数据结构是一种嵌套的结构或者说是单向继承的结构。基于最初的context（根context），开发者可以根据使用场景的不同定义自己的方法和数据来继承根context；正是context这种分层的组织结构，允许开发者在每一层context都定义一些不同的特性，这种层级式的组织也使得context易于扩展，职责清晰。
context包中的最基础的数据结构是一个Context接口：
type Context interface { // Done returns a channel that is closed when this Context is canceled // or times out. Done() &amp;lt;-chan struct{} // Err indicates why this context was canceled, after the Done channel // is closed. Err() error // Deadline returns the time when this Context will be canceled, if any.</description>
    </item>
    
    <item>
      <title>5分钟系列 -「Go Routine &amp; Channel」</title>
      <link>https://morven.life/notes/the_go_channel/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_go_channel/</guid>
      <description>说到Go语言，不得不提一下Go语言的并发编程。Go从语言层面增加了对并发编程的良好支持，不像Python、Java等其他语言使用Thread库来新建线程，同时使用线程安全队列库来共享数据。Go语言对于并发编程的支持依赖于Go语言的两个基础概念：Go Routine和Go Channel。
 Note: 也许我们还对并发(Concurrency)和并行(Parallelism)傻傻分不清楚，在这里再次强调两者的不同点：
Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once.
也就是说，并发是在同一时间处理多件事情，往往是通过编程的手段，目的是将CPU的利用率提到最高；而并行是在同一时间做多件事情，需要多核CPU的支持。
 Go Routine Go Routine是Go语言并行编程的核心概念之一，有人将它称作为“协程”，是比Thread更轻量级的并发单元，最小Go Routine只需极少的栈内存(大约是4~5KB)，这样十几个Go Routine的规模可能体现在底层就是五六个线程的大小，最高同时运行成千上万个并发任务；同时，Go语言内部实现了Go Routine之间的内存共享使得它比Thread更高效，更易用，我们不必再使用类似于晦涩难用的线程安全的队列库来同步数据。
创建Go Routine 要创建一个Go Routine，我们只需要在函数调⽤语句前添加go关键字，Go语言的调度器会自动将其安排到合适的系统线程上执行。实际上，我们在并发编程的过程中经常将一个大的任务分成好几块可以并行的小任务，为每一个小任务创建一个Go Routine。当一个程序启动时，其主函数即在一个单独的Go Routine中运行，我们叫它main routine，然后在主函数中使用go关键字来创建其他的Go Routine：
func subTask() { i := 0 for { i++ fmt.Printf(&amp;quot;new goroutine: i = %d\n&amp;quot;, i) time.Sleep(1 * time.Second) } } func main() { go subTask() // Create go rountine to execute sub task i := 0 // main goroutine for { i++ fmt.</description>
    </item>
    
    <item>
      <title>5分钟系列 -「Go Interface &amp; Composition」</title>
      <link>https://morven.life/notes/the_go_interface_and_composition/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_go_interface_and_composition/</guid>
      <description>Go语言接口与鸭子类型的关系 什么是“鸭子类型”？
 If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck.
 以上引用自维基百科的解释描述了什么是“鸭子类型”，所谓鸭子类型，是动态编程语言的一种对象推断策略，它更关注对象能如何被使用，而不是对象的类型本身。
传统的静态语言，如Java, C++等，它们必须显示声明实现了某个接口，之后，才能用在任何需要这个接口的地方，否则编译也不会通过，这也是静态语言比动态语言更安全的原因。但是Go语言作为一门“现代”静态语言，使用的是动态编程语言的对象推断策略，它更关注对象能如何被使用，而不是对象的类型本身。也就是说，Go语言引入了动态语言的便利，同时又会进行静态语言的类型检查，因此，它采用了折中的做法：不要求类型显示地声明实现了某个接口，只要实现了相关的方法即可，编译器就能检测到。
举个例子，下面的代码片段先定义一个接口，和使用此接口作为参数的函数：
type IGreeting interface { greeting() } func sayHello(i IGreeting) { i.greeting() }  接下来再定义两个结构体：
type A struct {} func (a A) greeting() { fmt.Println(&amp;quot;Hi, I am A!&amp;quot;) } type B struct {} func (b B) greeting() { fmt.Println(&amp;quot;Hi, I am B!</description>
    </item>
    
    <item>
      <title>从零开始认识iptables</title>
      <link>https://morven.life/notes/the_knowledge_of_iptables/</link>
      <pubDate>Sat, 20 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_knowledge_of_iptables/</guid>
      <description>在使用Linux的过程中，很多人和我一样经常接触iptables，但却只知道它是用来设置Linux防火墙的工具，不知道它具体是怎么工作的。今天，我们就从零开始认识一下Linux下iptables的具体工作原理。
iptables是Linux上常用的防火墙软件netfilter项目的一部分，所以要讲清楚iptables，我们先理一理什么是防火墙？
什么是防火墙 简单来说，防火墙是一种网络隔离工具，部署于主机或者网络的边缘，目标是对于进出主机或者本地网络的网络报文根据事先定义好的规则做匹配检测，规则匹配成功则对相应的网络报文做定义好的处理（允许，拒绝，转发，丢弃等）。防火墙根据其管理的范围来分可以将其划分为主机防火墙和网络防火墙；根据其工作机制来区分又可分为包过滤型防火墙（netfilter）和代理服务器（Proxy）。我们接下来在这篇笔记中主要说说**包过滤型防火墙（netfilter）。
 Note: 也有人将tcp_warrpers也划分为防火墙的一种，它是根据服务程序软件的名称来处理网络数据包的工具。
 包过滤型防火墙的工作原理 包过滤型防火墙主要依赖于Linux内核软件netfilter，它是一个Linux内核“安全框架”，而iptables是内核软件netfilter的配置工具，工作于用户空间。iptables/netfilter组合就是Linux平台下的过滤型防火墙，并且这个防火墙软件是免费的，可以用来替代商业防火墙软件，来完成网络数据包的过滤，修改，重定向以及网络地址转换（nat）等功能。
 Note: 在有些Linux发行版上，我们可以使用systemctl start iptables来启动iptables服务，但需要指出的是，iptables 并不是也不依赖于守护进程，它只是利用Linux内核提供的功能。
 Linux网络管理员通过配置iptables规则以及对应的网路数据包处理逻辑，当网络数据包符合这样的规则时，就做执行预先定义好的相应的处理逻辑。可以简单的总结为：
IF network_pkg match rule; THEN handler FI  其中规则可以包括匹配数据报文的源地址，目的地址，传输层协议（TCP/UDP/ICMP/..）以及应用层协议（HTTP/FTP/SMTP/..）等，处理逻辑就是根据规则所定义的方法来处理这些数据包，如放行（accept），拒绝（reject），丢弃（drop）等。
而netfilter是工作于内核空间当中的一系列网络（TCP/IP）协议栈的钩子（hook），为内核模块在网络协议栈中的不同位置注册回调函数（callback）。也就是说，在数据包经过网络协议栈的不同位置时做相应的由iptables配置好的处理逻辑。 netfilter中的五个钩子（这里也称为五个关卡）PRE_ROUTING，INPUT，FORWARD，OUTPUT，POST_ROUTING，网络数据包的流向图如下图所示：
 当主机/网络服务器网卡收到一个数据包之后进入内核空间的TCP/IP协议栈进行层层解封装 刚刚进入网络层的数据包通过PRE_ROUTING关卡时，要进行一次路由选择，当目标地址为本机地址时，数据进入INPUT，非本地的目标地址进入FORWARD（需要本机内核支持IP_FORWARD），所以目标地址转换通常在这个关卡进行 INPUT：经过路由之后送往本地的数据包经过此关卡，所以过滤INPUT包在此点关卡进行 FORWARD：经过路由选择之后要转发的数据包经过此关卡，所以网络防火墙通常在此关卡配置 OUTPUT：由本地用户空间应用进程产生的数据包过此关卡，所以OUTPUT包过滤在此关卡进行 POST_ROUTING：刚刚通过FORWARD和OUTPUT关卡的数据包要通过一次路由选择由哪个接口送往网络中，经过路由之后的数据包要通过POST_ROUTING此关卡，源地址转换通常在此点进行  上面提到的这些处于网络（TCP/IP）协议栈的“关卡”，在iptables的术语里叫做“链（chain）”，内置的链包括上面提到的5个：
 PreRouting Forward Input Output PostRouting  一般的场景里面，数据包的流向基本是：
 到本主机某进程的报文：PreRouting -&amp;gt; Input -&amp;gt; Process -&amp;gt; Output -&amp;gt; PostRouting 由本主机转发的报文：PreRouting -&amp;gt; Forward -&amp;gt; PostRouting  iptables的四表五链 iptables默认有五条链（chain），分别对应上面提到的五个关卡，PRE_ROUTING，INPUT，FORWARD，OUTPUT，POST_ROUTING，这五个关卡分别由netfilter的五个钩子函数来触发。但是，为什么叫做“链”呢？ 我们知道，iptables/netfilter防火墙对经过的数据包进行“规则”匹配，然后执行相应的“处理”。当报文经过某一个关卡时，这个关卡上的“规则”不止一条，很多条规则会按照顺序逐条匹配，将在此关卡的所有规则组织称“链”就很适合，对于经过的数据包按照顺序逐条匹配“规则”。
另外一个问题是，每一条“链”上的一串规则里面有些功能是相似的，比如，A类规则都是对IP或者端口进行过滤，B类规则都是修改报文，我们考虑能否将这些功能相似的规则放到一起，这样管理iptables规则会更方便。iptables把具有相同功能的规则集合叫做“表”，并且定一个四种表：
 filter：负责过滤功能；与之对应的内核模块是iptables_filter nat：Network Address Translation，网络地址转换功能，典型的比如SNAT，DNAT；与之对应的内核模块是iptables_nat mangle：解包报文，修改并封包；与之对应的内核模块是iptables_mangle raw：关闭nat表上启用的连接追踪机制；与之对应的内核模块是iptables_raw  这样，Linux网络管理员所定义的iptables“规则”都存在于这四张表中。</description>
    </item>
    
    <item>
      <title>编写健壮的Shell脚本</title>
      <link>https://morven.life/notes/writing-robust-shell-scripts/</link>
      <pubDate>Mon, 06 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/writing-robust-shell-scripts/</guid>
      <description>写Shell脚本应该已经成为程序员必须掌握的技能了。因为Shell脚本简单易上手的特性，在日常工作中，我们经常使用Shell脚本来自动化应用的部署测试，环境的搭建与清理等等。殊不知，Shell脚本也会有各种坑，经常导致Shell脚本因为各种原因不能正常执行成功。实际上，编写健壮可靠的Shell脚本也是有一定的技巧的，今天我们就来一一说明。
set -euxo pipefail 在执行Shell脚本的时候，通常都会创建一个新的Shell，比如，当我们执行：
bash script.sh  Bash会创建一个新的Shell来执行script.sh，同时也默认给定了这个执行环境的各种参数。set命令可以用来修改Shell环境的运行参数，不带任何参数的set命令，会显示所有的环境变量和Shell函数。对于所有可以定制的运行参数，请查看官方手册，我们重点介绍其中最常用的四个。
set -x 默认情况下，Shell脚本执行后只显示运行结果，不会展示结果是哪一行代码的输出，如果多个命令连续执行，它们的运行结果就会连续输出，导致很难分清一串结果是什么命令产生的。
set -x用来在运行结果之前，先输出执行的那一行命令，行首以+表示是命令而非命令输出，同时，每个命令的参数也会展开，我们可以清晰地看到每个命令的运行实参，这对于Shell的debug来说非常友好。
#!/bin/bash set -x v=5 echo $v echo &amp;quot;hello&amp;quot; # output: # + v=5 # + echo 5 # 5 # + echo hello # hello  实际上，set -x还有另一种写法set -o xtrace。
set -u Shell脚本不像其他高级语言，如Python, Ruby等，Shell脚本默认不提供安全机制，举个简单的例子，Ruby脚本尝试去读取一个没有初始化的变量的内容的时候会报错，而Shell脚本默认不会有任何提示，只是简单地忽略。
#!/bin/bash echo $v echo &amp;quot;hello&amp;quot; # output: # # hello  可以看到，echo $v输出了一个空行，Bash完全忽略了不存在的$v继续执行后面的命令echo &amp;quot;hello&amp;quot;。这其实并不是开发者想要的行为，对于不存在的变量，脚本应该报错且停止执行来防止错误的叠加。set -u就用来改变这种默认忽略未定义变量行为，脚本在头部加上它，遇到不存在的变量就会报错，并停止执行。
#!/bin/bash set -u echo $a echo bar # output: # .</description>
    </item>
    
    <item>
      <title>Webpack使用小结</title>
      <link>https://morven.life/notes/the_webpack_summary/</link>
      <pubDate>Sun, 20 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_webpack_summary/</guid>
      <description>分而治之是软件工程领域的重要思想，对于复杂度日益增加的前端也同样适用。一般前端团队选择合适的框架之后就要开始考虑开发维护的效率问题。而模块化是目前前端领域比较流行的分而治之手段。 Javascript模块化已经有很多规范和工具，例如CommonJS/AMD/requireJS/CMD/ES6 Module，在上篇文章中有详细的介绍。CSS模块化基本要依靠Less, Sass以及Stylus等于处理器的import/minxin特性实现。而HTML以及HTML模版和其他资源比如图片的模块化怎么去处理呢？ 这也正是webpack要解决的问题之一。严格来说，webpack是一个模块打包工具（module bundler），它既不像requireJS和seaJS这样的模块加载器，也不像grunt和gulp这样优化前端开发流程的构建工具，像是两类工具的集合却又远不止如此。
Webpack是一个模块打包工具，它将JS、CSS、HTML以及图片等都视为模块资源，这些模块资源必然存在某种依赖关系，webpack就是通过静态分析各种模块文件之间的依赖关系，通过不同种类的Loader将所有模块打包成起来。
webpack VS Gulp 严格来说，Gulp与webpack并没有可比性。Gulp应该和Grunt属于同一类工具，能够优化前端工作流程，比如压缩合并JS、CSS ，预编译Typescript、Sass等。也就是说，我们可以根据需要配置插件，就可以将之前需要手动完成的任务自动化。webpack作为模块打包工具，可以和browserify相提并论。两者都是预编译模块化解决方案。相比requireJS、seaJS这类‘在线’模块化方案更加智能。因为是‘预编译’，不需要在浏览器中加载解释器。另外，你可以直接在本地编写JS，不管是 AMD / CMD / ES6 风格的模块化，都编译成浏览器认识的JS。
总之，Gulp只是一个流程构建工具，而webpack、browserify等是模块化解决方案。Gulp也可以配置seaJS、requireJS甚至webpack的插件。
避免多个配置文件 刚开始接触webpack的时候，不管是去浏览GitHub上面star数较多的webpack项目，还是搜索stack overflow上面赞成数较多的回答，发现很多人提倡在一个项目中针对开发和产品发布提供不同的配置文件，比如webpack.dev.config.js和webpack.prod.config.js。看起来很清晰，也可以让新手迅速上手老项目，但仔细研究就会发现，不通环境的配置文件大部分配置项基本相同。这与工程领域一直提倡的DRY（Don&amp;rsquo;t Repeat Yourself）原则相悖，于是就产生了另外一种做法，先生成一个common的webpack.common.config.js，然后再针对不同的环境去继承（其实就是require）common的配置文件。但是不管怎样，其实都是生成多个不同的配置文件。如果换个角度想想，这些配置文件虽然不同，但都遵循着node的逻辑，所以完全可以只维护一个配置文件，然后针对不同的环境传入不同的参数。如果你使用npm，则完全可以在package.json文件中这样写：
&amp;quot;scripts&amp;quot;: { &amp;quot;devs&amp;quot;: &amp;quot;cross-env DEV=1 webpack-dev-server --hot --inline&amp;quot;, &amp;quot;build&amp;quot;: &amp;quot;cross-env PROD=1 rm -rf ./build &amp;amp;&amp;amp; webpack --p&amp;quot; }  其中cross-env是个跨平台的环境变量设置工具，可以允许Unix风格环境变量设置通用在window平台。 这样只维护一个webpack.config.js配置文件，然后在配置文件中处理自定义的参数。怎么处理自定义参数呢？这里我们使用webpack自带插件definePlugin提供魔力变量（magic globals）来处理：
plugins: [ new webpack.DefinePlugin ({ __DEV__: JSON.stringify(JSON.parse(process.env.DEV || &#39;false&#39;)), __PROD__: JSON.stringify(JSON.parse(process.env.PROD || &#39;false&#39;)) }) ]  然后在配置文件的其他地方就可以根据设定的环境变量更有针对性地配置不同插件等。甚至在业务逻辑中也可以这样针对不同环境做针对性地调试，比如在开发环境下可以AJAX可以调试本地mock数据，然后在发布的时候，可以正常访问服务端数据。
if (__DEV__) { // code for dev //.</description>
    </item>
    
    <item>
      <title>Javascript模块化开发</title>
      <link>https://morven.life/notes/developing-modular-javascript/</link>
      <pubDate>Sun, 16 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/developing-modular-javascript/</guid>
      <description>随着互联网时代的到来，前端技术更新速度越来越快。起初只要在script标签中嵌入几行代码就能实现一些基本的用户交互，到现在随着Ajax，jQuery，MVC以及MVVM的发展，Javascript代码量变得日益庞大复杂。 网页越来越像桌面程序，需要一个团队分工协作、进度管理、单元测试等等&amp;hellip;&amp;hellip;开发者不得不使用软件工程的方法，管理网页的业务逻辑。 Javascript模块化开发，已经成为一个迫切的需求。理想情况下，开发者只需要实现核心的业务逻辑，其他都可以加载别人已经写好的模块。 但是，Javascript不是一种模块化编程语言，它不支持&amp;rdquo;类&amp;rdquo;（class），更遑论&amp;rdquo;模块&amp;rdquo;（module）了。直到前不久ES6正式定稿，Javascript才开始正式支持&amp;rdquo;类&amp;rdquo;和&amp;rdquo;模块&amp;rdquo;，但还需要很长时间才能完全投入实用。
什么是模块化 模块是任何大型应用程序架构中不可缺少的一部分，一个模块就是实现特定功能的代码区块或者文件。模块可以使我们清晰地分离和组织项目中的代码单元。在项目开发中，通过移除依赖，松耦合可以使应用程序的可维护性更强。有了模块，开发者就可以更方便地使用别人的代码，想要什么功能，就加载什么模块。模块开发需要遵循一定的规范，否则就会混乱不堪。
Javascript社区做了很多努力，在现有的运行环境中，实现&amp;rdquo;模块&amp;rdquo;的效果。本文总结了当前＂Javascript模块化编程＂的最佳实践，说明如何投入实用。
Javascript模块化基本写法 在第一部分，将讨论基于传统Javascript语法的模块化写法。
原始写法 模块就是实现特定功能的一组方法。 只要把不同的函数（以及记录状态的变量）简单地放在一起，就算是一个模块。
function func1(){ //... } function func2(){ //... }  上面的函数func1()和func2()，组成一个模块。使用的时候，直接调用就行了。 这种做法的缺点很明显：&amp;rdquo;污染&amp;rdquo;了全局变量，无法保证不与其他模块发生变量名冲突，而且模块成员之间看不出直接关系。
对象写法 为了解决上面的缺点，可以把模块写成一个对象，所有的模块成员都放到这个对象里面。
var moduleA = new Object({ _count : 0, func1 : function (){ //... }, func2 : function (){ //... } });  上面的函数func1()和func2(），都封装在moduleA对象里。使用的时候，就是调用这个对象的属性。
moduleA.func1();  但是，这样的写法会暴露所有模块成员，内部状态可以被外部改写。比如，外部代码可以直接改变内部计数器的值。
moduleA._count = 3;  立即执行函数写法 使用&amp;rdquo;立即执行函数&amp;rdquo;（Immediately-Invoked Function Expression，IIFE），可以达到不暴露私有成员的目的。
var moduleA = (function(){ var _count = 0; var func1 = function(){ //.</description>
    </item>
    
    <item>
      <title>JSON Web Token</title>
      <link>https://morven.life/notes/the_jwt_quick_start/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_jwt_quick_start/</guid>
      <description>近几年，前后端分离大行其道。在典型的前后端分离的应用架构中，后端主要作为Model层，为前端提供数据访问API。前后端之间的通信需要在不可信（Zero Trust）的异构网络之间进行，为了保证数据安全可靠地在客户端与服务端之间传输，实现服务端的客户端认证就显得非常重要。而HTTP协议本身是无状态的，实现服务端的客户端认证的基础是记录客户端和服务端的对话状态。
我们最熟悉的服务端认证客户端的方式就是基于Session/Cookie的状态记录方式，服务端在第一次请求时声生成对应的Session发送给客户端保存在Cookie中，同时Session信息还会保存在服务器端，然后客户端之后对于服务器端的每次请求都需要带上Cookie，服务器端取出相应Session并与保存的Session信息进行对比，以实现身份的认证。
这种模式最大的问题是，没有分布式架构，无法支持横向扩展。如果使用一个服务器，该模式完全没有问题。但是，如果它是服务器群集或面向服务的跨域体系结构的话，则需要一个统一的session数据库库来保存会话数据实现共享，这样负载均衡下的每个服务器才可以正确的验证用户身份。
举例来说，某企业同时有两个不同的网站A和网站B提供服务，如何做到用户只需要登录其中一个网站，然后它就会自动登录到另一个网站？
一种解决方案是使用听过持久化Session的基础设施（如Redis），写入Session数据到持久层。收到新的客户端请求后，服务端从从持久层查找对应的Session信息。这种方案的优点在于架构清晰，而缺点是架构修改比较费劲，整个服务的验证逻辑层都需要重写，工作量相对较大。而且由于依赖于持久层的数据库或者问题系统，会有单点风险，如果持久层失败，整个认证体系都会挂掉。
儿JWT另辟蹊径，基于Token（令牌）认证客户端，也就是说只需要在每次客户端的请求的HTTP头部附上 对应的Token，由服务器端去检查Token的签名来确保Token没有被篡改，这样通过客户端保存数据，而服务器根本不保存会话数据，每个请求都被发送回服务器端认证。
什么是JWT(JSON Web Token) 根据官方的定义，JWT是一套开放的标准（RFC 7519），它定义了一套简洁（compact）且安全（URL-safe）的方案，可以在客户端和服务器之间传输JSON格式的Token信息。
JWT工作原理 JWT服务端认证的基本原理是在服务器身份验证之后，将生成一个JSON对象并将其发送回用户，如下所示。
{ &amp;quot;username&amp;quot;: &amp;quot;morvencao&amp;quot;, &amp;quot;role&amp;quot;: &amp;quot;Admin&amp;quot;, &amp;quot;expire&amp;quot;: &amp;quot;2017-02-08 12:45:43&amp;quot; }  之后，当客户端与服务器端通信时，客户端需要在请求中发回这个JSON对象。服务器仅依赖于这个JSON对象的内容来认证客户端。为了防止中间人（man-in-middle）篡改数据，服务器将在生成JSON对象时添加签名。但服务器不保存任何会话数据，即服务器变为无状态，使其更容易扩展。
JWT的数据结构 一个典型的JWT的数据结构看起来如下图所示：
JWT对象为一个很长的字符串，字符之间通过&amp;rdquo;.&amp;ldquo;分隔符分为三个子串，各字串之间也没有换行符。每一个子串表示了一个功能块，总共有以下三个部分：
 JWT头  JWT头部分是一个描述JWT元数据的JSON对象，通常如下所示：
{ &amp;quot;alg&amp;quot;: &amp;quot;HS256&amp;quot;, &amp;quot;typ&amp;quot;: &amp;quot;JWT&amp;quot; }  在上面的代码片段中，alg属性表示签名使用的算法，默认为HMAC SHA256（HS256）；typ属性表示令牌的类型，JWT令牌统一写为JWT；最后，使用Base64URL算法将上述JSON对象转换为字符串保存。
 有效载荷  有效载荷部分，是JWT的主体内容部分，也是一个JSON对象，包含需要传递的数据。JWT指定七个默认字段供选择：
iss：发行人 exp：到期时间 sub：主题 aud：用户 nbf：在此之前不可用 iat：发布时间 jti：JWT ID用于标识该JWT  除以上默认字段外，我们还可以自定义私有字段，如下例所示：
{ &amp;quot;sub&amp;quot;: &amp;quot;xxxxxxxxx&amp;quot;, &amp;quot;username&amp;quot;: &amp;quot;morvencao&amp;quot;, &amp;quot;role&amp;quot;: &amp;quot;Admin&amp;quot;, &amp;quot;expire&amp;quot;: &amp;quot;2017-02-08 12:45:43&amp;quot; }   Note: 默认情况下JWT是未加密的，任何人都可以解读其内容，因此不要构建隐私信息字段，存放保密信息，以防止信息泄露。</description>
    </item>
    
    <item>
      <title>SSH协议以及端口转发</title>
      <link>https://morven.life/notes/the_knowledge_of_ssh/</link>
      <pubDate>Thu, 19 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_knowledge_of_ssh/</guid>
      <description>SSH估计是每台Linux机器的标配了。日程工作中程序员在本机写完Code之后，很少在本机上直接部署测试，经常需要通过SSH协议登录到实验室的Linux主机上验证。实际上SSH具备多种功能，不仅仅是远程登录这么简单，今天我们就详细探讨一下SSH协议以及它的高级功能-端口转发。
SSH的原理 SSH是一种网络协议，用于计算机之间的加密登录，也就是说这种登陆是安全的。SSH协议之所以安全，是因为它基于非对称加密。基本的过程可以描述为：
 客户端通过SSH user@remote-host发起登录远程主机的请求 远程主机收到请求之后，将自己的公钥发给客户端 客户端使用这个公钥加密登录密码之后发给远程主机 远程主机使用自己的私钥，解密登陆请求，获得登录密码，如果正确，则建立SSH通道，之后所有客户端和远程主机的数据传输都要加密发送  看似很完美是吗？其实有个问题，如果有人中途拦截了登录请求，将自己伪造的公钥发送给客户端，客户端其实并不能识别这个公钥的可靠性，因为SSH协议并不像HTTPS协议那样，公钥是包含在证书中心CA来颁发的证书之中。所以有攻击者（中间人攻击-Man-in-the-middle-attack）拦截客户端到远程主机的登陆请求，伪造公钥来获取远程主机的登录密码，SSH协议的安全机制就荡然无存了。
说实话，SSH协议本身确实无法阻止这种攻击形式，最终还是依靠终端用户自身来识别并规避风险。
比如，我们在第一次登录某一台远程主机的时候，会得到如下提示：
$ ssh user@remote-host The authenticity of host &#39;10.30.110.230 (10.30.110.230)&#39; can&#39;t be established. ECDSA key fingerprint is SHA256:RIXlybA1rgf4mbnWvLuOMAxGRQQFgfnM2+YbYLT7aQA. Are you sure you want to continue connecting (yes/no)?  这个提示的意思是说无法确定远程主机的真实性，只能得到它的指纹(fingerprint)，需要你确认是否信任这个返回的公钥。这里所说的&amp;rdquo;指纹&amp;rdquo;是RSA公钥的MD5哈希结果。我们知道为了保证RSA私钥的安全性，一般RSA公钥设置基本都不小于1024位，很难直接让终端用户去确认完整的RSA公钥，于是通过MD5哈希函数将之转化为128位的指纹，就很容易识别了。实际上，有很多网络应用程序都是用RSA公钥指纹来让终端用户识别公钥的可靠性。
具体怎么决定是依赖于终端用户了，所以推荐的做法是将远程主机的公钥保存在合适的地方方便核对。这是，如果用户决定接受这个返回的公钥，系统会继续提示：
Warning: Permanently added &#39;10.30.110.230&#39; (RSA) to the list of known hosts.  紧接着就是用户输入密码来登录远程主机。同时远程主机的公钥会被保存在$HOME/.ssh/known_hosts这个文件中，下次登录的时候就不需要用户再次核对指纹了。每个SSH用户都有自己的known_hosts文件，此外系统也有一个这样的文件，通常是/etc/ssh/ssh_known_hosts，保存一些对所有用户都可信赖的远程主机的公钥。
除了使用密码登录，SSH协议还支持公钥登录。这里的公钥不再是远程主机的公钥，而是客户端的RSA公钥。原理很简单：
 用户将客户端的RSA公钥保存在远程主机上 客户端向远程主机发起登录请求 远程主机会向客户端发送一段随机字符串 客户端用自己的RSA私钥加密后再发送给远程主机 远程主机使用保存的的RSA公钥进行解密，如果解密成功则代表客户端是可信的，不需要密码就能确认身份  在客户端生成RSA公私钥对，一般使用ssh-keygen。举例来说，我们要生成2048位RSA密钥对：
$ ssh-keygen -b 2048 -t rsa -f foo_rsa Generating public/private rsa key pair.</description>
    </item>
    
    <item>
      <title>Linux的启动流程</title>
      <link>https://morven.life/notes/the_knowledge_of_linux/</link>
      <pubDate>Tue, 10 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_knowledge_of_linux/</guid>
      <description>和Window等其他操作系统一样，linux的启动也分为两个阶段：引导（boot）和启动（startup）。引导阶段开始于打开电源开关，接下来板载程序BIOS的开始POST上电自检主过程，结束于内核初始化完成。启动阶段接管剩余的工作，直到操作系统初始化完成进入可操作状态，并能够执行用户的功能性任务。
我们不花过多篇幅讲解引导阶段的硬件板载程序加载运行的过程。事实上，由于在板载程序上很多行为基本上固定的，程序员很难介入，所以接下来主要讲讲主板的引导程序如何加载内核程序以及控制权交给linux操作系统之后的各个服务的启动流程。
GRUB引导加载程序 所谓引导程序，一个用于计算机寻找操作系统内核并加载其到内存的智能程序，通常位于硬盘的第一个扇区，并由BIOS载入内存执行。为什么需要引导程序，而不是直接由BIOS加载操作系统？原因是BOIS只会自动加载硬盘的第一个扇区的512字节的内容，而操作系统的大小远远大于这个值，所以才会先加载引导程序，然后通过引导程序加载程序加载操作系统到内存中。
目前，各个Linux发行版主流的引导程序是GRUB(GRand Unified BootLoader)。GRUB的作用有以下几个： - 加载操作系统的内核 - 拥有一个可以让用户选择到底启动哪个系统的的菜单界面 - 可以调用其他的启动引导程序，来实现多系统引导
GRUB1现在已经逐步被弃用，在大多数现代发行版上它已经被GRUB2所替换。GRUB2通过/boot/grub2/grub.cfg进行配置，最终GRUB定位和加载linux内核程序到内存中，并转移控制权到内核程序。
内核程序 内核程序的相关文件位于/boot目录下，这些内核文件均带有前缀vmlinuz。内核文件都是以一种自解压的压缩格式存储以节省空间。在选定的内核加载到内存中并开始执行后，在其进行任何工作之前，内核文件首先必须从压缩格式解压自身。
# ll /boot/ total 152404 drwxr-xr-x 4 root root 4096 Nov 29 15:34 ./ drwxr-xr-x 22 root root 335 Jan 16 12:22 ../ -rw-r--r-- 1 root root 190587 Aug 10 2018 config-3.2.0-3-amd64 -rw-r--r-- 1 root root 190611 Oct 2 12:22 config-3.2.0-4-amd64 drwxr-xr-x 5 root root 4096 Nov 29 15:33 grub/ -rw-r--r-- 1 root root 39413114 Nov 29 15:33 initrd.</description>
    </item>
    
    <item>
      <title>创建私有CA以及颁发SSL证书</title>
      <link>https://morven.life/notes/create_pki_with_openssl/</link>
      <pubDate>Mon, 24 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/create_pki_with_openssl/</guid>
      <description>在上一篇文章深入理解PKI系统的与数字证书中介绍了PKI系统的基本组成以及CA认证中心的主要作用，以及X.509证书基本标准。今天，我们继续应用已经学习的理论知识构建一套自己的PKI/CA数字证书信任体系。
SSL证书生成工具 有以下两种常见的工具来生成RSA公私密钥对:
 Note: 有些情形只需要公私密钥对就够了，不需要数字证书，比如私有的SSH服务。但是对于一些要求身份认证的情形，则需要对公钥进行数字签名形成数字证书。
  ssh-keygen openssl genrsa  实际上ssh-keygen底层也是使用OpenSSL提供的库来生成密钥。
ssh-keygen 举例来说，我们要生成2048位RSA密钥对：
$ ssh-keygen -b 2048 -t rsa -f foo_rsa Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in foo_rsa. Your public key has been saved in foo_rsa.pub. The key fingerprint is: b8:c4:5f:2a:94:fd:b9:56:9d:5b:fd:96:02:5a:7e:b7 user@oasis The key&#39;s randomart image is: +--[ RSA 2048]----+ | | | | | | | .</description>
    </item>
    
    <item>
      <title>深入理解PKI系统的与CA中心</title>
      <link>https://morven.life/notes/the_pki_and_digital_certificate/</link>
      <pubDate>Wed, 12 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_pki_and_digital_certificate/</guid>
      <description>在上一篇文章数字签名与数字证书中介绍了数字签名以及数字证书的一些基础知识以及数字证书的作用，但是并没有提到数字证书的管理，比如数字证书的申请，数字证书的文件格式等知识。这篇文章将继续探讨数字证书的管理知识。
说到数字证书的管理，不得不提到一个词，PKI(Publick Key Infrastructure)，即公钥基础设施，是一种遵循既定标准的密钥管理平台，它能够为所有网络应用提供加密和数字签名等密码服务及所必需的密钥和证书管理体系。简单来说，可以理解为利用之前提到过的供私钥非对称加密技术为应用提供加密和数字签名等密码服务以及与之相关的密钥和证书管理体系。
 PKI既不是一个协议，也不是一个软件，它是一个标准，在这个标准之下发展出的为了实现安全基础服务目的的技术统称为PKI
 PKI的组成 PKI作为一个实施标准，有一系列的组件组成：
 CA(Certificate Authority)中心(证书签发)：是PKI的”核心”，即数字证书的申请及签发机关，CA必须具备权威性的特征，它负责管理PKI结构下的所有用户(包括各种应用程序)的证书，把用户的公钥和用户的其他信息捆绑在一起，在网上验证用户的身份，CA还要负责用户证书的黑名单登记和黑名单发布。
 X.500目录服务器(证书保存)：X.500目录服务器用于&amp;rdquo;发布&amp;rdquo;用户的证书和黑名单信息，用户可通过标准的LDAP协议查询自己或其他人的证书和下载黑名单信息。
 基于SSL(Secure socket layer)的安全web服务器：Secure Socket Layer(SSL)协议最初由Netscape企业发展，现已成为网络用来鉴别网站和网页浏览者身份，以及在浏览器使用者及网页服务器之间进行加密通讯的全球化标准。
 Web(安全通信平台)：Web有Web Client端和Web Server端两部分，分别安装在客户端和服务器端，通过具有高强度密码算法的SSL协议保证客户端和服务器端数据的机密性、完整性、身份验证。
 自开发安全应用系统：自开发安全应用系统是指各行业自开发的各种具体应用系统，例如银行、证券的应用系统等。完整的PKI包括:
1) 认证政策的制定 2) 认证规则 3) 运作制度的制定 4) 所涉及的各方法律关系内容 5) 技术的实现等
  CA 认证中心CA(Certificate Authority)，是一个负责发放和管理数字证书的权威机构，它作为电子商务交易中受信任的第三方，承担公钥体系中公钥的合法性检验的责任。CA为每个使用公开密钥的用户发放一个数字证书，以实现公钥的分发并证明其合法性。作为PKI的核心部分，CA实现了PKI中一些很重要的功能:
 接收验证最终用户数字证书的申请 确定是否接受最终用户数字证书的申请-证书的审批 向申请者颁发、拒绝颁发数字证书-证书的发放 接收、处理最终用户的数字证书更新请求-证书的更新 接收最终用户数字证书的查询、撤销 产生和发布证书废止列表(CRL) 数字证书的归档 密钥归档 历史数据归档  X.509标准 整个PKI体系中有很多格式标准，PKI的标准规定了PKI的设计、实施和运营，规定了PKI各种角色的&amp;rdquo;游戏规则&amp;rdquo;。如果两个PKI应用程序之间要想进行交互，只有相互理解对方的数据含义，交互才能正常进行，标准的作用就是提供了数据语法和语义的共同约定。PKI中最重要的标准，它定义了公钥证书的基本结构。
X.509是定义了公钥证书结构的基本标准，是目前非常通用的证书格式。X.509标准在PKI中起到了举足轻重的作用，PKI由小变大，由原来网络封闭环境到分布式开放环境，X.509起了很大作用，可以说X.509标准是PKI的雏形。PKI是在X.509标准基础上发展起来的。理论上只要为一个网络应用程序创建的证书符合ITU-T X.509国际标准，就可以用于任何其他符合X.509标准的网络应用。对于符合X.509标准的数字证书，必须保证公钥及其所有者(Subject)的姓名是一致的，同时，认证者(Issuer)总是CA或由CA指定的人。X.509数字证书是一些标准字段的集合，这些字段包含有关用户或设备及其相应公钥的信息。X.509标准定义了证书中应该包含哪些信息，并描述了这些信息是如何编码的(即数据格式)，所有的X.509证书包含以下数据：
 版本号(Version)：指出该证书使用了哪种版本的X.509标准（版本1、版本2或是版本3），版本号会影响证书中的一些特定信息，目前的版本为3 序列号(Serial Number)： 标识证书的唯一整数，由证书颁发者分配的本证书的唯一标识符 签名算法标识符： 用于签证书的算法标识，由对象标识符加上相关的参数组成，用于说明本证书所用的数字签名算法。例如，SHA-1和RSA的对象标识符就用来说明该数字签名是利用RSA对SHA-1杂凑加密 认证机构的数字签名：这是使用证书发布者私钥生成的签名，以确保这个证书在发放之后没有被撰改过 认证机构： 证书颁发者的可识别名（DN），是签发该证书的实体唯一的CA的X.500名字。使用该证书意味着信任签发证书的实体。(注意：在某些情况下，比如根或顶级CA证书，发布者自己签发证书) 有效期限(Validity)： 证书起始日期和时间以及终止日期和时间；指明证书在这两个时间内有效 主题信息(Subject)：证书持有人唯一的标识符(或称DN-distinguished name)这个名字在 Internet上应该是唯一的 公钥信息(Public-Key)： 包括证书持有人的公钥、算法(指明密钥属于哪种密码系统)的标识符和其他相关的密钥参数 颁发者唯一标识符(Issuer)：标识符—证书颁发者的唯一标识符，仅在版本2和版本3中有要求，属于可选项  除了以上字段之外，X.</description>
    </item>
    
    <item>
      <title>数字签名与数字证书</title>
      <link>https://morven.life/notes/the_digital_signature_and_digital_certificate/</link>
      <pubDate>Mon, 06 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_digital_signature_and_digital_certificate/</guid>
      <description>在之前的密码学笔记主要是介绍密码学的基础知识，包括两种加密算法的原理，引入在非对称加密算法中数字证书（Digital Certificate）的概念。这篇笔记将继续探讨什么是数字证书，不过在了解它之前，先得知道什么是数字签名（Digital Signature）。
关于数字签名和数字证书的概念，有一篇非常经典的文章，本文的大部分内容来自于那篇文章，喜欢读英文原版的请移步至：http://www.youdzone.com/signature.html
Bob生成了自己的（公钥，私钥）对，将私钥自己保存，并将公钥分发给了他的朋友们：Pat，Susan，Daug
Susan要给Bob写一封保密的信件，写完后用Bob的公钥加密，就可以达到保密的效果。Bob收到信件之后用自己的私钥来解密，就可以看到信件的内容。这里假设Bob的私钥没有泄露（私钥是十分敏感的信息，一定要注意保管，泄露私钥那么文章里很多假设都不成立），即使信件被别人截获，信件内容也无法解密，也就是说这封信的内容不会有第三个人知道。
Bob给Susan回信，决定采用&amp;rdquo;数字签名&amp;rdquo;：他写完后先用Hash函数，生成信件的摘要（Digest），然后，在使用自己的私钥，对这个摘要进行加密，生成&amp;rdquo;数字签名&amp;rdquo;（Digital Signature）。
Bob将这个数字签名，附在信件里面，一起发给Susan。
Susan收到信件之后，对信件本身使用相同的Hash函数，得到当前信件内容的摘要，同时，取下数字签名，用Bob的公钥解密，得到原始信件的摘要，如果两者相同就说明信件的内容没有被修改过。由此证明，这封信确实是Bob发出的。
但是，更复杂的情况出现了。Daug想欺骗Susan，他伪装成Bob制作了一对（公钥，私钥）对，并将公钥分发给Susan，Susan此时实际保存的是Daug的公钥，但是还以为这是Bob的公钥。因此，Daug就可以冒充Bob，用自己的私钥做成&amp;rdquo;数字签名&amp;rdquo;写信给Susan，而Susan用假的鲍勃公钥进行解密。一切看起来完美无缺？
Susan觉得有些不对劲，因为她并不确定这个公钥是不是真正属于Bob的。于是她想到了一个办法，要求Bob去找&amp;rdquo;证书中心&amp;rdquo;（Certificate Authority，简称CA），为公钥做认证。证书中心用证书中心的私钥，对Bob的公钥和一些相关信息一起加密，生成&amp;rdquo;数字证书&amp;rdquo;（Digital Certificate）。
一旦Bob拿到数字证书以后，就可以放心写信给任何人了。只需要在信件内容的后面附上数字签名的同时，再附上数字证书就行了。
Susan收到信件之后，首先使用用CA的公钥（一般都是公开的）解开数字证书，就可以拿到Bob真实可信的公钥了，然后就能用此公钥解密数字签名进一步验证信件内容是否被篡改过。
由此可见，&amp;rdquo;数字证书&amp;rdquo;就是解决身份认证的问题，就如同现实中我们每一个人都要拥有一张证明个人身份的身份证或驾驶执照一样，以表明我们的身份或某种资格。数字证书是由权威公正的第三方机构即Certificate Authority(CA)中心签发的，确保信息的机密性和防抵赖性。对于一个大型的应用环境，认证中心往往采用一种多层次的分级结构，各级的认证中心类似于各级行政机关，上级认证中心负责签发和管理下级认证中心的证书，最下一级的认证中心直接面向最终用户。</description>
    </item>
    
    <item>
      <title>密码学基础</title>
      <link>https://morven.life/notes/the_basic_of_cryptology/</link>
      <pubDate>Tue, 16 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_basic_of_cryptology/</guid>
      <description>密码学（Cryptography） 密码学是研究编制密码和破译密码的技术科学。研究密码变化的客观规律，应用于编制密码以保守通信秘密的，称为编码学；应用于破译密码以获取通信情报的，称为破译学，总称密码学。 密码是通信双方按约定的法则进行信息特殊变换的一种重要保密手段。依照这些法则，变明文为密文，称为加密变换；变密文为明文，称为脱密变换。密码在早期仅对文字或数码进行加、脱密变换，随着通信技术的发展，对语音、图像、数据等都可实施加、脱密变换。
密码算法 什么是密码算法（Cryptography Algorithm），通常是指加、解密过程所使用的信息变换规则，是用于信息加密和解密的数学函数。对明文进行加密时所采用的规则称作加密算法，而对密文进行解密时所采用的规则称作解密算法。加密算法和解密算法的操作通常都是在一组密钥的控制下进行的。
什么是密钥？密钥（Secret Key）是密码算法中的一个可变参数，通常是一组满足一定条件的随机序列。用于加密算法的叫做加密密钥，用于解密算法的叫做解密密钥，加密密钥和解密密钥可能相同，也可能不相同。
加密算法根据根据密钥的不同分为两类，对称加密算法(Symmetric-key Algorithm)和非对称加密算法(Asymmetric Key Encryption Algorithm)。
对称加密 首先，让我们先从一个情景开始讲起。
比如张三学习比李四好，李四就想在考试的时候让张三“帮助”一下自己，当然，他们俩不可能像我们平常对话一样说，第一题选A，第二题选B等等，为什么？因为监考老师明白他俩在谈论什么，也就是说这种沟通交流方式属于“明文”，所以李四就想：“我需要发明一种，只有我和张三明白的交流方式”，那李四做了什么呢？恩，李四去找张三说：“当我连续咳嗽三声的时候你看我，然后如果我摸了下左耳朵，说明你可以开始给我传答案了，如果没反应，那说明我真的是在咳嗽&amp;hellip;”， 然后，怎么传答案呢？很简单，“你摸左耳朵代表A, 摸右耳朵代表B，左手放下代表C，右手放下代表D”，好了，这就是他们的“算法(规则)”，将信息的一种形式(A,B,C,D)，这里我们称为“明文”，转换成了另一种形式(摸左耳朵，摸右耳朵，放左手，放右手)，这里称为“密文”，经过这种转换，很显然监考老师不会明白这些“密文”，这样，张三和李四就通过“密文”的形式实现了信息的交换。
对称加密算法也叫单钥加密（Private Key Cryptography），加密和解密过程都用同一套密钥。历史上，人类传统的加密方法都是前一种，比如二战期间德军用的Enigma电报密码，莫尔斯电码也可以看作是一种私钥加密方法。
结合前面的例子对应一下，密钥就是“将(A,B,C,D)转换成(摸左耳朵，摸右耳朵，放左手，放右手)”这么一个规则。
 实务上，这组密钥成为在两个或多个成员间的共同秘密，以便维持专属的通讯联系。
 这句话很好理解了吧，密钥是张三和李四间共同的秘密！只有他俩事先知道。 所以，为什么叫对称加密呢，你可以这么理解，一方通过密钥将信息加密后，把密文传给另一方，另一方通过这个相同的密钥将密文解密，转换成可以理解的明文。他们之间的关系如下：
明文 &amp;lt;-&amp;gt; 密钥 &amp;lt;-&amp;gt; 密文  目前常见的对称加密算法有：
DES、3DES、AES、Blowfish、IDEA、RC5、RC6。  非对称加密 非对称加密算法也称为双钥加密（Public Key Cryptography），加密和解密过程用的是两套密钥。非对称加密是一种比对称加密更加优秀的加密算法。对称加密的密钥只有一把，所以密钥的保存变得很重要。一旦密钥泄漏，密码也就被破解。 在非对称加密的情况下，密钥有两把，一把是公开的公钥，还有一把是不公开的私钥。 对称加密的原理如下：
 公钥和私钥是一一对应的关系，有一把公钥就必然有一把与之对应的、独一无二的私钥，反之亦成立。 所有的（公钥, 私钥）对都是不同的。 用公钥可以解开私钥加密的信息，反之亦成立。 同时生成公钥和私钥应该相对比较容易，但是从公钥推算出私钥，应该是很困难或者是不可能的。  在对称加密体系中，公钥用来加密信息，私钥用来数字签名。 比如，李四想给张三发送密文。于是李四开始给张三发消息：
李四： “hi哥们，我想给你发个密文，把你的公钥给我发过来。” 张三： “没问题的，这是我的公钥： d#8yHE8eU#hb*!neb，用这个公钥加密你的信息后给我发过来吧” 李四： “这是我想对你说的话： *&amp;amp;#@uehuu(**#eehu&amp;amp;$##bfeu&amp;amp;&amp;amp;”  为什么公开问公钥？非对称解密算法的强大之处就在这里！公钥可以随意分发，所以即使第三方截取了，也只是知道该公钥而已，但是要是想解密使用该公钥加密的密文！只有一个人可以办得到！就是张三！ 为什么？李四使用张三的公钥加密的信息，只有张三的公钥所对应的私钥，这里就是“张三私钥”，该私钥才可以解密！所以，没有张三私钥的第三方即时截取了这些密文，也破解不了！或者更严格的说在有限时间内比如说几千年内是暴力破解不出的！
非对称加密算法，首先要有一对key，一个被称为私钥（Private Key），一个成为公钥（Public Key），然后可以把公钥分发给想给你传密文的用户，然后用户使用该公钥加密过得密文，只有使用私钥才能解密，也就是说，只要保存好你的私钥，就能确保别人想给你发的密文不被破解。正因为，这种加密是单向的，所以被称为非对称加密算法。
这种加密算法应用非常广泛，SSH, HTTPS, TLS，电子证书，电子签名，电子身份证等等。
因为任何人都可以生成自己的（公钥，私钥）对，所以为了防止有人散布伪造的公钥骗取信任，就需要一个可靠的第三方机构来生成经过认证的（公钥，私钥）对。这就是数字证书的作用了，接下来的文章将会继续探讨什么是数字签名以及数字证书。</description>
    </item>
    
    <item>
      <title>字符编码的前世今生</title>
      <link>https://morven.life/notes/the_character_encoding/</link>
      <pubDate>Sun, 12 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://morven.life/notes/the_character_encoding/</guid>
      <description>字符编码问题看似无关紧要，常常被忽略，但是对字符编码知识没有一个完整系统的认识，实际编码过程中会让我们吃尽苦头。今天，我们就来看一看字符编码的前世今生。
ASCII-一切的起源 字符编码主要是解决如何使用计算机的方式来表达特定的字符，但是有计算机基础理论知识的人都知道，计算机内部所有的数据都是基于二进制，每个二进制位（bit）有0和1两种状态，我们可以组合多个二进位来表达更大的数值，例如八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。这就是说，我们可以一个字节来映射用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从00000000到11111111，这样就建立了最初的计算机数值到自然语言字符最基本的映射关系。上个世纪60年代，美国国家标准协会ANSI制定了一个标准，规定了常用字符的集合以及每个字符对应的编号，这就是ASCII字符集（Character Set），也称ASCII码。ASCII码规定了英语字符与二进制位之间的对应关系。
ASCII码一共规定了128个字符的编码（包括32个不能打印出来的控制符号），比如空格SPACE是32（二进制表示为00100000），大写的字母A是65（二进制表示为01000001）。这128个符号只需要占用了一个字节的后面7位，最前面的一位统一规定为0。
按照ASCII字符集编码和解码就是简单的查表过程。例如将字符序列编码为二进制流写入存储设备，只需要在ASCII字符集中依次找到字符对应的字节，然后直接将该字节写入存储设备即可，解码二进制流就是相反的过程。
各种OEM编码的衍生 当计算机发展起来的时候，人们逐渐发现，ASCII字符集里的128个字符不能满足他们的需求。在英语国家，128个字符编码足矣，但是对于非英语国家，人们无法在ASCII字符集中找到他们的基本字符。比如，在法语中，字母上方有注音符号，它就无法用ASCII码表示。于是有些人就在想，ASCII字符只是使用了一个字节的前128个变换，后面的128位完全可以利用起来，于是一些一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。
但是，这里又出现了新的问题。不同的国家有不同的字母，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。比如，130在法语编码中代表了é，在希伯来语编码中却代表了字母Gimel (ג)，在俄语编码中又会代表另一个符号。不同的OEM字符集导致人们无法跨机器传播交流各种信息。例如甲发了一封简历résumés给乙，结果乙看到的却是rגsumגs，因为é字符在甲机器上的OEM字符集中对应的字节是0×82，而在乙的机器上，由于使用的OEM字符集不同，对0×82字节解码后得到的字符却是ג。
但是尽管出现了不同的OEM编码，所有这些编码方式中，0--127表示的符号是一样的，不一样的只是128--255的这一段代表的字符。
至于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是GB2312，使用两个字节表示一个汉字，所以理论上最多可以表示256 x 256 = 65536个符号。
 Note: 中文编码的问题很复杂，这篇笔记就深入讨论，但需要指出的是虽然都是用多个字节表示一个符号，但是GB类的汉字编码与后文的Unicode和UTF-8是毫无关系的。
 从ANSI标准到国家标准再到ISO标准 不同ASCII衍生字符集的出现，让文档交流变得非常困难，因此各种组织都陆续进行了标准化流程。例如美国ANSI组织制定了ANSI标准字符编码，ISO组织制定的各种ISO标准字符编码，还有各国也会制定一些国家标准字符集，例如中国的GBK，GB2312和GB18030。
每台计算机的操作系统都会预装这些标准的字符集还有平台专用的字符集，这样只要使用标准字符集编写文档就可以达到很高的通用性。例如用GB2312字符集编写的文档，在中国大陆内的任何机器上都能正确显示。当然，也可以在一台计算机上阅读多个不同国家语言的文档，但是前提是计算机必须得安装该文档使用的字符集。
Unocode的出现 虽然通过使用不同字符集，我们可以在一台计算机上查阅不同语言的文档，但是仍然无法解决一个问题：在一份文档中显示所有字符。那时的人们就在想，如果有一种编码，能够映射世界上所有的语言符号，每一个符号都给予一个无二义的编码，那么乱码问题就会消失。这就是Unicode字符集，就像它的名字都表示的，这是一种所有符号的编码。
Unicode字符集包括了目前人类使用的所有字符，当然是一个很大的集合，现在的规模可以容纳100多万个符号。每个符号的编码都不一样，比如，U+0639表示阿拉伯字母Ain，U+0041表示英语的大写字母A，U+4E25表示汉字严。Unicode字符集将所有字符按照使用上的频繁度划分为17个层面（Plane），每个层面上有2^16=65536个字符空间。具体的符号对应表，可以查询unicode.org，或者专门的汉字对应表。
Unicode的问题 有了Unicode之后，人们常会问一个问题？
 Unicode是需要两个字节存储吗？
 其实Unicode只是定义了一个庞大的、全球通用的字符集，并为每个字符规定了唯一确定的二进制代码，却没有规定这个二进制代码应该如何存储。
例如，汉字严的Unicode是十六进制数#4E25，转换成二进制数足足有15位（100111000100101），也就是说，这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。
这样的话就会有两个严重的问题，第一个问题是，如何才能区别Unicode和ASCII？计算机无法知道三个字节是表示一个字符，还是分别表示三个字符。第二个问题是，英文字母只用一个字节表示就够了，但是基于Unicode的规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。
它们造成的结果是：
 出现了Unicode的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示Unicode。 Unicode在很长一段时间内无法推广，直到互联网的出现。  UTF-8 随着互联网的普及，人们强烈要求出现一种统一的Unicode的编码方式。UTF-8就是在互联网上使用最广的一种Unicode的编码实现方式。其他实现方式还包括UTF-16（字符用两个字节或四个字节表示）和UTF-32（字符用四个字节表示），不过在互联网上基本不用。
由于UCS-2/UTF-16对于ASCII字符使用两个字节进行编码，存储和处理效率相对低下，并且由于ASCII字符经过UTF-16编码后得到的两个字节，高字节始终是0×00，很多C语言的函数都将此字节视为字符串末尾从而导致无法正确解析文本。因此UTF-16刚推出的时候遭到很多西方国家的抵触，大大影响了Unicode的推行。后来聪明的人们发明了UTF-8编码，解决了这个问题。
 Note：一定要记住，UTF-8是Unicode的编码实现方式之一。
 UTF-8最大的一个特点，就是它是一种“变长”的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。
UTF-8的编码规则简单实用：
 对于单字节的符号，字节的第一位设为0，后面7位为这个符号的Unicode码。因此对于英文字母，UTF-8编码和ASCII编码是完全相同的 对于n字节的符号（n &amp;gt; 1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的Unicode码  下表总结了编码规则，字母x表示可用编码的位：
   Unicode符号范围 UTF-8编码方式     十六进制表示 二进制表示   0000 0000-0000 007F 0xxxxxxx   0000 0080-0000 07FF 110xxxxx 10xxxxxx   0000 0800-0000 FFFF 1110xxxx 10xxxxxx 10xxxxxx   0001 0000-0010 FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx    基于上表，解读UTF-8编码就非常简单。如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。</description>
    </item>
    
  </channel>
</rss>